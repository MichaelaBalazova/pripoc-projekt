{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # fitness is the macro avg of f1-score\n",
    "                fitness = f1_score(y_test, y_pred, average='macro')\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 100, num_eval = 100):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 45 features - 0.9991253906655226\n",
      "2 . run = 53 features - 0.9984694125378355\n",
      "3 . run = 49 features - 0.9989067533176503\n",
      "4 . run = 49 features - 0.9991253664366916\n",
      "5 . run = 53 features - 0.9989067533176503\n",
      "---------------------------------------\n",
      "BEST --> 45 FEATURES - fitness = 0.9991253906655226\n",
      "executed time = 1850.6932654380798 sec\n",
      "---------------------------------------\n",
      "45 features, f1 = 0.9991253906655226\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=12))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 39 features - 0.9984694961644989\n",
      "2 . run = 46 features - 0.9984694125378355\n",
      "3 . run = 48 features - 0.9986880496550374\n",
      "4 . run = 45 features - 0.9984694961644989\n",
      "5 . run = 43 features - 0.9989067533176503\n",
      "---------------------------------------\n",
      "BEST --> 43 FEATURES - fitness = 0.9989067533176503\n",
      "executed time = 1960.5864799022675 sec\n",
      "---------------------------------------\n",
      "43 features, f1 = 0.9989067533176503\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 50 features - 0.9984694961644989\n",
      "2 . run = 52 features - 0.998906723241311\n",
      "3 . run = 50 features - 0.9989067533176503\n",
      "4 . run = 44 features - 0.9982508291176966\n",
      "5 . run = 40 features - 0.9980322093543559\n",
      "---------------------------------------\n",
      "BEST --> 50 FEATURES - fitness = 0.9989067533176503\n",
      "executed time = 1509.8689925670624 sec\n",
      "---------------------------------------\n",
      "50 features, f1 = 0.9989067533176503\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 40 features - 0.9986881218382724\n",
      "2 . run = 47 features - 0.9986881218382724\n",
      "3 . run = 48 features - 0.9989066927455553\n",
      "4 . run = 50 features - 0.998906723241311\n",
      "5 . run = 52 features - 0.9986880859982841\n",
      "---------------------------------------\n",
      "BEST --> 50 FEATURES - fitness = 0.998906723241311\n",
      "executed time = 1183.0436635017395 sec\n",
      "---------------------------------------\n",
      "50 features, f1 = 0.998906723241311\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 48 features - 0.9989067533176503\n",
      "2 . run = 38 features - 0.9986880496550374\n",
      "3 . run = 52 features - 0.9984694125378355\n",
      "4 . run = 47 features - 0.9986881218382724\n",
      "5 . run = 46 features - 0.9982508762334465\n",
      "---------------------------------------\n",
      "BEST --> 48 FEATURES - fitness = 0.9989067533176503\n",
      "executed time = 1208.0398201942444 sec\n",
      "---------------------------------------\n",
      "48 features, f1 = 0.9989067533176503\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (45, 0.9991253906655226, 'gwo'),\n",
       " (43, 0.9989067533176503, 'ga'),\n",
       " (50, 0.9989067533176503, 'fa'),\n",
       " (50, 0.998906723241311, 'pso'),\n",
       " (48, 0.9989067533176503, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(45, 0.9991253906655226, 'gwo'),\n",
       " (43, 0.9989067533176503, 'ga'),\n",
       " (50, 0.9989067533176503, 'fa'),\n",
       " (48, 0.9989067533176503, 'ba'),\n",
       " (50, 0.998906723241311, 'pso'),\n",
       " (88, 0.9982508762334465, 'all')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_sorted_f1 = [(44, 0.9995626709361498, 'pso'),\n",
    " (42, 0.9991253664366916, 'ga'),\n",
    " (47, 0.9989067533176503, 'gwo'),\n",
    " (46, 0.9986880496550374, 'fa'),\n",
    " (42, 0.9986880496550374, 'ba'),\n",
    " (88, 0.9982508762334465, 'all')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([40, 90, 0.9981, 0.9996])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
