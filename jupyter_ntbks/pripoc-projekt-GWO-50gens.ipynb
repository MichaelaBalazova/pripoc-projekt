{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 50, num_eval = 50):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 29 features - 1.0066649592534176\n",
      "2 . run = 33 features - 1.00277028208157\n",
      "3 . run = 26 features - 1.0103827954991929\n",
      "4 . run = 31 features - 1.005356899618452\n",
      "5 . run = 29 features - 1.0060152698540896\n",
      "---------------------------------------\n",
      "BEST --> 26 FEATURES - fitness = 1.0103827954991929\n",
      "executed time = 291.91130018234253 sec\n",
      "---------------------------------------\n",
      "26 features, f1 = 0.9965016582353929\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=40))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 33 features - 1.0023371089345494\n",
      "2 . run = 37 features - 1.0005369292184707\n",
      "3 . run = 36 features - 1.0018467827614188\n",
      "4 . run = 33 features - 1.0036361453227027\n",
      "5 . run = 36 features - 1.001413839147581\n",
      "---------------------------------------\n",
      "BEST --> 33 FEATURES - fitness = 1.0036361453227027\n",
      "executed time = 318.4805643558502 sec\n",
      "---------------------------------------\n",
      "33 features, f1 = 0.9969388673293293\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 31 features - 1.0057894350911678\n",
      "2 . run = 36 features - 1.0011974124711382\n",
      "3 . run = 36 features - 1.002063417763215\n",
      "4 . run = 37 features - 1.0009699184183845\n",
      "5 . run = 36 features - 0.9996817953585627\n",
      "---------------------------------------\n",
      "BEST --> 31 FEATURES - fitness = 1.0057894350911678\n",
      "executed time = 315.5070722103119 sec\n",
      "---------------------------------------\n",
      "31 features, f1 = 0.9973760993100751\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 29 features - 1.0077472378628094\n",
      "2 . run = 32 features - 1.0051188432195755\n",
      "3 . run = 30 features - 1.0047871029336775\n",
      "4 . run = 25 features - 1.0104372135058166\n",
      "5 . run = 26 features - 1.010815715292563\n",
      "---------------------------------------\n",
      "BEST --> 26 FEATURES - fitness = 1.010815715292563\n",
      "executed time = 295.60027289390564 sec\n",
      "---------------------------------------\n",
      "26 features, f1 = 0.996938950955969\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 34 features - 1.0030681800682357\n",
      "2 . run = 35 features - 1.000813176155692\n",
      "3 . run = 38 features - 1.0018591353567317\n",
      "4 . run = 38 features - 1.0012096212094217\n",
      "5 . run = 36 features - 1.0022797263752563\n",
      "---------------------------------------\n",
      "BEST --> 34 FEATURES - fitness = 1.0030681800682357\n",
      "executed time = 319.9584767818451 sec\n",
      "---------------------------------------\n",
      "34 features, f1 = 0.9971574011384438\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (26, 0.9965016582353929, 'gwo'),\n",
       " (33, 0.9969388673293293, 'ga'),\n",
       " (31, 0.9973760993100751, 'fa'),\n",
       " (26, 0.996938950955969, 'pso'),\n",
       " (34, 0.9971574011384438, 'ba')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (31, 0.9973760993100751, 'fa'),\n",
       " (34, 0.9971574011384438, 'ba'),\n",
       " (26, 0.996938950955969, 'pso'),\n",
       " (33, 0.9969388673293293, 'ga'),\n",
       " (26, 0.9965016582353929, 'gwo')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([25, 90, 0.9962, 0.9985])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
