{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 50, num_eval = 50):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 35 features - 1.00319469155491\n",
      "2 . run = 34 features - 1.0026351385772063\n",
      "3 . run = 37 features - 1.0022684599291234\n",
      "4 . run = 34 features - 1.0045835580794777\n",
      "5 . run = 39 features - 1.0010487787094422\n",
      "---------------------------------------\n",
      "BEST --> 34 FEATURES - fitness = 1.0045835580794777\n",
      "executed time = 1227.6864285469055 sec\n",
      "---------------------------------------\n",
      "34 features, f1 = 0.9986880859982841\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=12))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 37 features - 1.0016191256809523\n",
      "2 . run = 33 features - 1.0040691479064459\n",
      "3 . run = 34 features - 1.0028518315972126\n",
      "4 . run = 39 features - 1.0003993236980437\n",
      "5 . run = 32 features - 1.0044695614464092\n",
      "---------------------------------------\n",
      "BEST --> 32 FEATURES - fitness = 1.0044695614464092\n",
      "executed time = 1300.2939565181732 sec\n",
      "---------------------------------------\n",
      "32 features, f1 = 0.996938950955969\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 40 features - 0.9998352819308118\n",
      "2 . run = 35 features - 1.001679112353125\n",
      "3 . run = 31 features - 1.0044909235841954\n",
      "4 . run = 31 features - 1.0036244476883118\n",
      "5 . run = 36 features - 1.002063481442953\n",
      "---------------------------------------\n",
      "BEST --> 31 FEATURES - fitness = 1.0044909235841954\n",
      "executed time = 1293.6691658496857 sec\n",
      "---------------------------------------\n",
      "31 features, f1 = 0.9960644715252546\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 30 features - 1.0060864787680204\n",
      "2 . run = 33 features - 1.0032029218769345\n",
      "3 . run = 33 features - 1.003419544120966\n",
      "4 . run = 34 features - 1.0032849041478444\n",
      "5 . run = 35 features - 1.0016795920850814\n",
      "---------------------------------------\n",
      "BEST --> 30 FEATURES - fitness = 1.0060864787680204\n",
      "executed time = 1229.1136572360992 sec\n",
      "---------------------------------------\n",
      "30 features, f1 = 0.9967203489239262\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 37 features - 1.0001040152764291\n",
      "2 . run = 36 features - 1.0009808955337434\n",
      "3 . run = 35 features - 1.0012463646183185\n",
      "4 . run = 35 features - 1.0018961750044968\n",
      "5 . run = 33 features - 1.0032031177559655\n",
      "---------------------------------------\n",
      "BEST --> 33 FEATURES - fitness = 1.0032031177559655\n",
      "executed time = 1157.256386756897 sec\n",
      "---------------------------------------\n",
      "33 features, f1 = 0.9965014657467666\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (34, 0.9986880859982841, 'gwo'),\n",
       " (32, 0.996938950955969, 'ga'),\n",
       " (31, 0.9960644715252546, 'fa'),\n",
       " (30, 0.9967203489239262, 'pso'),\n",
       " (33, 0.9965014657467666, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34, 0.9986880859982841, 'gwo'),\n",
       " (88, 0.9982508762334465, 'all'),\n",
       " (32, 0.996938950955969, 'ga'),\n",
       " (30, 0.9967203489239262, 'pso'),\n",
       " (33, 0.9965014657467666, 'ba'),\n",
       " (31, 0.9960644715252546, 'fa')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAAJDCAYAAAA4mcP/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZRedZ3v+8+3KmGITJpEIYNAK2qChggVQCYRmhYUiTI02ExqK7TK8tj3qg2t51wvnIjTavty2+FwulHsheA5CjRXUbGRsUWlaEwaRIamGQLSRtQgYMSS3/2jnmAREqkMO1UFr9dateqp/fz2fn6bbZl3dn71VLXWAgAAdKNvrCcAAADPZIIbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOjSq4K6qg6vq1qq6o6pOXc3z21fV5VW1pKqurKpZI577WFXd1Ps4esT2A6rqX3vbz62qSb3tVVVn9V5rSVXtuiFOFAAAxsLTBndV9Sf5dJJDksxN8uaqmrvKsE8m+WJrbV6S05Oc2dv39Ul2TTI/yR5J3l9VW1VVX5JzkxzTWnt5kruTnNg71iFJdup9nJTks+t1hgAAMIZGc4d79yR3tNbubK09luSCJAtXGTM3yeW9x1eMeH5ukqtaa0OttUeSLE5ycJKpSX7TWrutN+7bSY7oPV6Y4XhvrbXvJdmmqrZbh3MDAIAxN5rgnpnk3hFfL+1tG2lxfh/Mb0qyZVVN7W0/pKqmVNW0JK9JMjvJz5JMrqqB3j5H9raP9vUAAGBCmDSKMbWabav+Pvj3Jfm7qnpLkquT3JdkqLV2WVUtSPLdJMuSXNfb3qrqmCSfqqpNk1yWZGgtXi9VdVKGl5zkOc95zm4ve9nLRnEqAACw7m644Yaftdamr80+ownupfn93eckmZXk/pEDWmv3Jzk8SapqiyRHtNaW955blGRR77kvJbm9t/26JPv2tv9JkpeM9vV6+5+d5OwkGRgYaIODg6M4FQAAWHdVdffa7jOaJSXXJ9mpqnasqk2SHJPkklVeeFrvByGT5LQk5/S29/eWlqSq5iWZl+G72amq5/c+b5rkr5J8rrf/JUlO6L1byZ5JlrfWfrK2JwYAAOPB097hbq0NVdUpSb6VpD/JOa21m6vq9CSDrbVLkuyf5MyqahleUvLu3u6Tk1xTVUnyUJLjWmsrl468v6oOzXD0f7a19p3e9kuTvC7JHUkeTfLW9T9NAAAYG9XaU5ZHTziWlAAAsDFU1Q2ttYGnH/l7o1nDDQAAT/Lb3/42S5cuzYoVK8Z6Kp3YbLPNMmvWrEyePHm9jyW4AQBYa0uXLs2WW26ZHXbYIb3lw88YrbU8+OCDWbp0aXbcccf1Pt6ofrU7AACMtGLFikydOvUZF9tJUlWZOnXqBrt7L7gBAFgnz8TYXmlDnpvgBgCADgluAADokOAGAGDCOuOMM/Kyl70sBx10UN785jfn4x//eHbbbbckyeLFi1NVueeee5IkL3rRi/Loo4/m7rvvzoEHHph58+blwAMPfOL5rghuAAAmpMHBwXz1q1/NjTfemAsvvDCDg4Pp6+vLihUr8tBDD+Waa67JwMBArrnmmtx99915/vOfnylTpuSUU07JCSeckCVLluTYY4/Ne97znk7n6W0BAQCYkK699tosXLgwm2++eZLkDW94Q5Jkr732yr/8y7/k6quvzl//9V/nm9/8Zlpr2XfffZMk1113XS688MIkyfHHH58PfOADnc7THW4AACakNf3G9H333feJu9oLFy7M4sWLc+2112a//fZb7fiu323FHW4AADa4od89ng9fcnN+snxFXj5z6zWOu+m+5dlu683y4cN2zqT+tbsXvM8+++Tkk0/OaaedlqGhoXz961/PO97xjuy333750Ic+lP322y99fX153vOel0svvTRnnnlmkuE74BdccEGOP/74nHfeedlnn33W61yfjuAGAGCD6++r/PuyR/L9/3gwl//4p2sc11fJnn80Nf19a3+XecGCBTnssMOyyy67ZPvtt8/AwEC23nrr7LDDDknyxB3tffbZJ0uXLs1zn/vcJMlZZ52Vt73tbfnEJz6R6dOn5/Of//zan+BaqDXdip9IBgYG2uDg4FhPAwDgWeOWW27JnDlz/uCYe3/+aP7kU1dnxW9/l9UVZyXZbHJ/vv1/7JdZz52yTvN4+OGHs8UWW+TRRx/Nfvvtl7PPPju77rrrOh1rVas7x6q6obU2sDbHsYYbAIBOzH7elHzw9XNWG9tJ0pJ86NA56xzbSXLSSSdl/vz52XXXXXPEEUdssNjekCwpAQCgM8fu8cJ8fclP8v3/eDCPjyjvlUtJ/mz3F67X8b/0pS+t5wy75w43AACdqap8/Mh52XRSf1au0q4km07qz8ePnNf5O4SMB4IbAIBOrbq0ZEMsJZlIBDcAAJ07do8X5lV/NDVJsteL1n8pyUQiuAEA6FxV5ZN/ukuO2m1WPnHULs+KpSQrCW4AADaKmdtsnk8ctUtmbrN5p6+zww475Gc/+1mSZIsttuj0tUZDcAMAQIcENwAAE9Yb3/jG7Lbbbtl5551z9tlnj/V0Vsv7cAMAMGGdc845ed7znpdf//rXWbBgQY444oixntJTCG4AACass846KxdddFGS5N57783tt98+xjN6KsENAMCEdOWVV+af//mfc91112XKlCnZf//9s2LFirGe1lMIbgAANrzfDSXf+EDy0P3JdrusedxPfphsNTM55ONJ/9ql6fLly/Pc5z43U6ZMyY9//ON873vfW89Jd0NwAwCw4fX1Jz+7Lbn7X5LbvrHmcdWX7LDP8Pi1dPDBB+dzn/tc5s2bl5e+9KXZc88912PC3RHcAABseFXJwk8nn9kj+e2K5Ilf7P6kQcmkTYfHrcMvwtl0003zjW88NebvuuuuJx4//PDDa33cDc3bAgIA0I3nbp/8yaKsPrYzvP21H0m2eWb/mnfBDQBAdwbeluyw7/DSkZGqL9lxv2S3t47NvDYiwQ0AQHdWLi2ZtGmSlctG1m8pyUQjuAEA6NZTlpY8O5aSrCS4AQDo3sqlJcmzZinJSoIbAIDuVSVv/Gwy/7hk4WeeFUtJVvK2gAAAbBzbzE7e+OmxnsVG5w43AAB0yB1uAAAmrDPOOCPnnXdeZs+enWnTpmW33XbL1ltvnbPPPjuPPfZYXvziF+cf//EfM2XKlDGbozvcAABMSIODg/nqV7+aG2+8MRdeeGEGBweTJIcffniuv/76LF68OHPmzMk//MM/jOk83eEGAGBCuvbaa7Nw4cJsvvnmSZI3vOENSZKbbropH/rQh/LLX/4yDz/8cF772teO5TQFNwAAE1Nrq/+V8W95y1ty8cUXZ5dddskXvvCFXHnllRt3YqsQ3AAAbHBDjw/loz/4aB545IHMnTp3jeN+9OCPsu1zts2pu5+aSX1rl6b77LNPTj755Jx22mkZGhrK17/+9bzjHe/Ir371q2y33Xb57W9/m/POOy8zZ85c39NZL4IbAIANrr/6c+fyOzP4wGCuWnrVGsf1pS8D2w6kv/rX+jUWLFiQww47LLvssku23377DAwMZOutt84ZZ5yRPfbYI9tvv31e8YpX5Fe/+tX6nMp6qzXdip9IBgYG2spF8gAAdO+WW27JnDlz/uCY+x6+L2+8+I35ze9+k5anNmelsmn/pvmnN/5TZmwxY53m8fDDD2eLLbbIo48+mv322y9nn312dt1113U61qpWd45VdUNrbWBtjuNdSgAA6MTMLWbm/Qvev9rYTpKWlvcveP86x3aSnHTSSZk/f3523XXXHHHEERsstjckS0oAAOjMUS85Kt+865sZfGDwSeG9cinJUS85ar2O/6UvfWl9p9g5d7gBAOhMVeWMvc/Ipv2bplLD21LZpH+TnLH3GamqMZ5h9wQ3AACdWnVpyYZYSjKRCG4AADp31EuOyoJtFyRJdt929/VeSjKRWMM9wQz97vF8+JKb85PlK/LymVuvcdxN9y3Pdltvlg8ftnMm9ft7FQAwtqoqi/ZelM8s/kzetcu7nhVLSVYS3BNMf1/l35c9ku//x4O5/Mc/XeO4vkr2/KOp6e979vyPGQAY37bbYrucsfcZYz2Njc6tzwmmqvLxI+dl00n9WVNKV5JNJ/Xn40fOe1b97REAYDwS3BPQ7OdNyQdfP2cN72iZtCQfOnROZj13ysacFgDARnXXXXflZS97WU488cTMmzcvRx55ZB599NGceuqpmTt3bubNm5f3ve99SZK77747Bx54YObNm5cDDzww99xzz0abp+CeoI7d44V51R9NzaorRvoq2etFU/Nnu79wbCYGALAR3XrrrTnppJOyZMmSbLXVVvm7v/u7XHTRRbn55puzZMmSfOhDH0qSnHLKKTnhhBOyZMmSHHvssXnPe96z0eYouCeo1S0tsZQEAHi2mT17dvbee+8kyXHHHZerr746m222Wd7+9rfnwgsvzJQpw//if9111+XP/uzPkiTHH398rr322o02R8E9ga26tMRSEgDg2WbVm4yTJ0/OD37wgxxxxBG5+OKLc/DBB49qvy55l5IJ7tg9XpivL/lJrrvzQUtJAIBxow0N5YFFizL0wH9ms7lz1zhuxc03Z9J222bbD34wNWnt0/See+7Jddddl1e96lU5//zzM3/+/Cxfvjyve93rsueee+bFL35xkmSvvfbKBRdckOOPPz7nnXde9tlnn3U+t7UluCe4qson/3SX/O23b8t7D3qJpSQAwPjQ35/H7rwzj14/mIevuGLN4/r6MmXBgqS/f51eZs6cOTn33HNz8sknZ6eddsqHP/zhHHrooVmxYkVaa/nUpz6VJDnrrLPytre9LZ/4xCcyffr0fP7zn1+n11sXgvsZYOY2m+cTR+0y1tMAAHhCVWW7RR/JnYcemvab3yRtNe+vVpXaZJPM+Miidb5p2NfXl8997nNP2vaDH/zgKeN22GGHfOc731mn11hf1nADANCJTWbNzAtO/avVx3aStJYXnHpqJs+cuXEntpEJbgAAOrPN0Udnyh67J32rZGdfX6bssUe2OfpP1/nYO+ywQ2666ab1nGH3BDcAAJ1ZubSkNtkkWblsZAMsJZlIBDcAAJ16ytKSZ8lSkpUENwAAnXtiaUmy3ktJJhrBDQBA56oqM848M1sffnhmnPmRZ8VSkpUENwAAG8XkGTMy4yOLMnnGjA1yvLvuuisvf/nLN8ixuiS4AQCgQ4IbAIAJa2hoKCeeeGLmzZuXI488Mo8++mhOP/30LFiwIC9/+ctz0kknpa3pfcA3EsENAMCEdeutt+akk07KkiVLstVWW+Uzn/lMTjnllFx//fW56aab8utf/zpf+9rXxnSOghsAgAlr9uzZ2XvvvZMkxx13XK699tpcccUV2WOPPfKKV7wi3/nOd3LzzTeP6RwnjemrAwDAelj13U6qKu9617syODiY2bNn58Mf/nBWrFgxRrMbJrgBANjgHv/d47nmy7fn4V+syPQXbrnGccvu+VW2eO5m2ffondLXv/aLL+65555cd911edWrXpXzzz8/++yzT7773e9m2rRpefjhh/OVr3wlRx555PqcynoT3AAAbHDVV/nFA4/kvtt/mbv+7cE1j6tkxku2SfWt2/tyz5kzJ+eee25OPvnk7LTTTnnnO9+ZX/ziF3nFK16RHXbYIQsWLFjXU9hgaqx/anNDGBgYaIODg2M9DQCAZ41bbrklc+bM+YNjHvrZr3P+6d/P0GOPr3HMpE368ub/a49sNXXzDT3F9ba6c6yqG1prA2tzHD80CQBAJ7aatnn2PnKnPzhm7yN3GpexvSEJbgAAOrPzvjMy8yXbJKusGKlKZr50m+y874b5rZPjmeAGAKAzVZUDTpiTSZOfnJ39k/tywAlznvIuI89Eowruqjq4qm6tqjuq6tTVPL99VV1eVUuq6sqqmjXiuY9V1U29j6NHbD+wqv61qn5YVddW1Yt7299SVct6239YVW/fECcKAMDYWN3SkmfDUpKVnja4q6o/yaeTHJJkbpI3V9XcVYZ9MskXW2vzkpye5Mzevq9PsmuS+Un2SPL+qtqqt89nkxzbWpuf5EtJPjTieF9urc3vffz9Op8dAADjwhNLS/LsWUqy0mjucO+e5I7W2p2ttceSXJBk4Spj5ia5vPf4ihHPz01yVWttqLX2SJLFSQ7uPdeSrIzvrZPcv26nAADAeFdVOfAtc/OyvbbLgSfOfVYsJVlpNME9M8m9I75e2ts20uIkR/QevynJllU1tbf9kKqaUlXTkrwmyezeuLcnubSqliY5PslHRxzviN7ylK9U1ewAADDhbfm8zXLgCXOy5fM222DHPOusszJnzpwce+yxG+yYG9pognt1f/1Y9c2735fk1VV1Y5JXJ7kvyVBr7bIklyb5bpLzk1yXZKi3z18meV1rbVaSzyf5m972/y/JDr3lKf+c5NzVTqrqpKoarKrBZcuWjeI0AAB4pvnMZz6TSy+9NOedd95YT2WNRhPcS/P7u9JJMiurLP9ord3fWju8tfbKJB/sbVve+7yotxb7oAzH++1VNT3JLq217/cO8eUke/XGP9ha+01v+/9MstvqJtVaO7u1NtBaG5g+ffpozhUAgGeQv/iLv8idd96Zww47LB/72Mey11575ZWvfGX22muv3HrrrWM9vSeMJrivT7JTVe1YVZskOSbJJSMHVNW0qlp5rNOSnNPb3t9bWpKqmpdkXpLLkvwiydZV9ZLePgcluaU3brsRhz5s5XYAABjpc5/7XGbMmJErrrgi73znO3P11VfnxhtvzOmnn56//uu/HuvpPWHS0w1orQ1V1SlJvpWkP8k5rbWbq+r0JIOttUuS7J/kzKpqSa5O8u7e7pOTXNNbFP9QkuNaa0NJUlXvSPLVqno8wwH+tt4+76mqwzK89OTnSd6yIU4UAIBnruXLl+fEE0/M7bffnqrKb3/727Ge0hOeNriTpLV2aYbXYo/c9t9GPP5Kkq+sZr8VGX6nktUd86IkF61m+2kZvksOAACj8l//63/Na17zmlx00UW56667sv/++4/1lJ4wquAGAIC18fjvfpfvfP5/5Fc//1lesOOL1jjuP++8I1tOnZ4D3npy+vr71/n1li9fnpkzh99I7wtf+MI6H6cLghsAgA2u+vry8/vvzdIf3ZQ7b/jBmsdVZdbcV6T6RvUL0NfoAx/4QE488cT8zd/8TQ444ID1OtaGJrgBANjgqiqv/Yv35gv/57sy9Nhjeeq7SidJpX/yJjn4ne9d51+Ec9dddyVJpk2blttuu+2J7WecccY6Ha8L6/dXCQAAWIOtn/+C7H/Cn2f1sZ0kLfuf8PZsNf35G3NaG53gBgCgM/P++JDM3vkVT7mDXVWZvfO8zPvjg8doZhuP4AYAoDMrl5b0T94kv/8F5uu/lGQiEdwAAKyT1ta0VOTJnrq0ZPwvJRntuY2G4AYAYK1tttlmefDBB0cdpiuXliQZ90tJWmt58MEHs9lmm22Q43mXEgAA1tqsWbOydOnSLFu2bNT7vPigN6RN3iwv3v+g/PjHP+5wdutvs802y6xZszbIsQQ3AABrbfLkydlxxx3Xer9dX7VXB7MZ3ywpAQCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOTRrrCQAAwDr73VDyjQ8kD92fbLfLmsf95IfJVjOTQz6e9G/cBBbcAABMXH39yc9uS+7+l+S2b6x5XPUlO+wzPH4js6QEAICJqypZ+Olk0qZJak2Dhp9f+Onh8RuZ4AYAYGJ77vbJnyxK0tYwoCWv/UiyzQs35qyeILgBAJj4Bt6W7LDv8NKRkaov2XG/ZLe3js28IrgBAHgmWO3SkrFdSrKS4AYA4JnhKUtLxnYpyUqCGwCAZ46VS0uSMV9KspLgBgDgmaMqeeNnk/nHJQs/M6ZLSVbyPtwAADyzbDM7eeOnx3oWT3CHGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADo0quCuqoOr6taquqOqTl3N89tX1eVVtaSqrqyqWSOe+1hV3dT7OHrE9gOr6l+r6odVdW1Vvbi3fdOq+nLvtb5fVTus/2kCAMDYeNrgrqr+JJ9OckiSuUneXFVzVxn2ySRfbK3NS3J6kjN7+74+ya5J5ifZI8n7q2qr3j6fTXJsa21+ki8l+VBv+58n+UVr7cVJPpXkY+t+egAAMLZGc4d79yR3tNbubK09luSCJAtXGTM3yeW9x1eMeH5ukqtaa0OttUeSLE5ycO+5lmRlfG+d5P7e44VJzu09/kqSA6uqRn9KAAAwfowmuGcmuXfE10t720ZanOSI3uM3Jdmyqqb2th9SVVOqalqS1ySZ3Rv39iSXVtXSJMcn+eiqr9daG0qyPMnUtTkpAAAYL0YT3Ku7u9xW+fp9SV5dVTcmeXWS+5IMtdYuS3Jpku8mOT/JdUmGevv8ZZLXtdZmJfl8kr9Zi9dLVZ1UVYNVNbhs2bJRnAYAAGx8ownupfn9XekkmZXfL/9IkrTW7m+tHd5ae2WSD/a2Le99XtRam99aOyjDMX17VU1Psktr7fu9Q3w5yV6rvl5VTcrwcpOfrzqp1trZrbWB1trA9OnTR3e2AACwkY0muK9PslNV7VhVmyQ5JsklIwdU1bSqWnms05Kc09ve31takqqal2ReksuS/CLJ1lX1kt4+ByW5pff4kiQn9h4fmeQ7rbWn3OEGAICJYNLTDWitDVXVKUm+laQ/yTmttZur6vQkg621S5Lsn+TMqmpJrk7y7t7uk5Nc0/uZx4eSHNdbl52qekeSr1bV4xkO8Lf19vmHJP9YVXdk+M72MRvkTAEAYAzUM+Hm8cDAQBscHBzraQAA8AxXVTe01gbWZh+/aRIAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ6MK7qo6uKpurao7qurU1Ty/fVVdXlVLqurKqpo14rmPVdVNvY+jR2y/pqp+2Pu4v6ou7m3fv6qWj3juv22IEwUAgLEw6ekGVFV/kk8nOSjJ0iTXV9UlrbUfjRj2ySRfbK2dW1UHJDkzyfFV9fokuyaZn2TTJFdV1Tdaaw+11vYd8RpfTfJPI453TWvt0PU9OQAAGGujucO9e5I7Wmt3ttYeS3JBkoWrjJmb5PLe4ytGPD83yVWttaHW2iNJFic5eOSOVbVlkgOSXLxupwAAAOPXaIJ7ZpJ7R3y9tLdtpMVJjug9flOSLatqam/7IVU1paqmJXlNktmr7PumJJe31h4ase1VVbW4qr5RVTuP8lwAAGDcGU1w12q2tVW+fl+SV1fVjUleneS+JEOttcuSXJrku0nOT3JdkqFV9n1z77mV/jXJ9q21XZL8v1nDne+qOqmqBqtqcNmyZaM4DQAA2PhGE9xL8+S70rOS3D9yQGvt/tba4a21Vyb5YG/b8t7nRa21+a21gzIc77ev3K93F3z3JF8fcayHWmsP9x5fmmRy7+74k7TWzm6tDbTWBqZPnz66swUAgI1sNMF9fZKdqmrHqtokyTFJLhk5oKqmVdXKY52W5Jze9v5eVKeq5iWZl+SyEbseleRrrbUVI461bVVV7/HuvTk+uC4nBwAAY+1p36WktTZUVack+VaS/iTntNZurqrTkwy21i5Jsn+SM6uqJbk6ybt7u09Ock2vnx9KclxrbeSSkmOSfHSVlzwyyTuraijJr5Mc01pbdQkLAABMCPVMaNmBgYE2ODg41tMAAOAZrqpuaK0NrM0+ftMkAAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQAUL7W8AABPQSURBVIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIdGFdxVdXBV3VpVd1TVqat5fvuquryqllTVlVU1a8RzH6uqm3ofR4/Yfk1V/bD3cX9VXdzbXlV1Vu+1llTVrhviRAEAYCw8bXBXVX+STyc5JMncJG+uqrmrDPtkki+21uYlOT3Jmb19X59k1yTzk+yR5P1VtVWStNb2ba3Nb63NT3Jdkgt7xzokyU69j5OSfHa9zhAAAMbQaO5w757kjtbana21x5JckGThKmPmJrm89/iKEc/PTXJVa22otfZIksVJDh65Y1VtmeSAJBf3Ni3McLy31tr3kmxTVdut5XkBAMC4MJrgnpnk3hFfL+1tG2lxkiN6j9+UZMuqmtrbfkhVTamqaUlek2T2Kvu+KcnlrbWH1uL1AABgQhhNcNdqtrVVvn5fkldX1Y1JXp3kviRDrbXLklya5LtJzs/w0pGhVfZ9c++5tXm9VNVJVTVYVYPLli0bxWkAAMDGN5rgXpon35WeleT+kQNaa/e31g5vrb0yyQd725b3Pi/qrdU+KMMxffvK/Xp3wXdP8vW1eb3ecc9urQ201gamT58+itMAAICNbzTBfX2Snapqx6raJMkxSS4ZOaCqplXVymOdluSc3vb+XlSnquYlmZfkshG7HpXka621FSO2XZLkhN67leyZZHlr7SfrcG4AADDmJj3dgNbaUFWdkuRbSfqTnNNau7mqTk8y2Fq7JMn+Sc6sqpbk6iTv7u0+Ock1VZUkDyU5rrU2cknJMUk+uspLXprkdUnuSPJokreu47kBAMCYq9aesjx6whkYGGiDg4NjPQ0AAJ7hquqG1trA2uzjN00CAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAh572bQFZN0OPD+WjP/hoHnjkgcydOneN43704I+y7XO2zam7n5pJfS4HAMAzjcLrSH/1587ld2bwgcFctfSqNY7rS18Gth1If/VvxNkBALCxWFLSkarKGXufkU37N02lVj8mlU36N8kZe5+R3i8HAgDgGUZwd2jmFjPz/gXvT8vqf7lQS8v7F7w/M7aYsZFnBgDAxiK4O3bUS47Kgm0XPOUud1/6svu2u+eolxw1RjMDAGBjENwdW93SEktJAACePQT3RrDq0hJLSQAAnj0E90aycmlJEktJAACeRQT3RlJVWbT3orzxxW/Mf9/7v1tKAgDwLOF9uDei7bbYLmfsfcZYTwMAgI3IHW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6NCksZ7AeNCGhvLAokUZeuA/s9ncuWsct+LmmzNpu22z7Qc/mJrkPx0AAE9PNSZJf38eu/POPHr9YB6+4oo1j+vry5QFC5L+/o03NwAAJjRLSpJUVbZb9JHUJpskVWsalNpkk8z4yKLUmsYAAMAqBHfPJrNm5gWn/lXS2uoHtJYXnHpqJs+cuXEnBgDAhCa4R9jm6KMzZY/dk75V/rP09WXKHntkm6P/dGwmBgDAhCW4R1jt0hJLSQAAWA+CexVPWVpiKQkAAOtBcK/GE0tLEktJAABYL4J7NaoqM848M1sffnhmnPkRS0kAAFhn3od7DSbPmJEZH1k01tMAAGCCc4cbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ4IbAAA6JLgBAKBDghsAADokuAEAoEOCGwAAOiS4AQCgQ6MK7qo6uKpurao7qurU1Ty/fVVdXlVLqurKqpo14rmPVdVNvY+jR2yvqlpUVbdV1S1V9Z7e9v2ranlV/bD38d82xIkCAMBYmPR0A6qqP8mnkxyUZGmS66vqktbaj0YM+2SSL7bWzq2qA5KcmeT4qnp9kl2TzE+yaZKrquobrbWHkrwlyewkL2utPV5Vzx9xvGtaa4dugPMDAIAxNZo73LsnuaO1dmdr7bEkFyRZuMqYuUku7z2+YsTzc5Nc1Vobaq09kmRxkoN7z70zyemttceTpLX203U/DQAAGJ9GE9wzk9w74uulvW0jLU5yRO/xm5JsWVVTe9sPqaopVTUtyWsyfFc7SV6U5OiqGqyqb1TVTiOO96qqWtzbvvNanhMAAIwbT7ukJEmtZltb5ev3Jfm7qnpLkquT3JdkqLV2WVUtSPLdJMuSXJdkqLfPpklWtNYGqurwJOck2TfJvybZvrX2cFW9LsnFSXbKKqrqpCQnJckLX/jCUZzG+PX47x7PNV++PQ//YkWmv3DLNY5bds+vssVzN8u+R++Uvn4/7woAMBGMJriX5vd3pZNkVpL7Rw5ord2f5PAkqaotkhzRWlvee25RkkW9576U5PYRx/1q7/FFST7fG//QiONeWlWfqapprbWfrfKaZyc5O0kGBgZW/QvAhFJ9lV888Ejuu/2XuevfHlzzuEpmvGSbVN/q/g4EAMB4NJrbpNcn2amqdqyqTZIck+SSkQOqalpVrTzWaRm+W52q6u8tLUlVzUsyL8llvXEXJzmg9/jVSW7rjdu2qqr3ePfeHNdcoc8AVZUDTpiTSZP/8OXon9yXA06Yk95/HgAAJoCnDe7W2lCSU5J8K8ktSf5Xa+3mqjq9qg7rDds/ya1VdVuSF6R3RzvJ5CTXVNWPMnw3+rje8ZLko0mOqKp/y/C7mry9t/3IJDdV1eIkZyU5prU2oe9gj8ZW0zbP3kc+ZeXMk+x95E7ZaurmG2lGAABsCPVMaNmBgYE2ODg41tNYb621/NOnbsx9t//ySavkVy4lWfjeV7q7DQAwhqrqhtbawNrs4yfvxpE1LS2xlAQAYOIS3OPM6paWWEoCADBxCe5xaOd9Z2TmS7ZJksx86TbZed8ZYzwjAADW1WjeFpCNrKpy4Fvm5gdf+4/sfuiOlpIAAExggnuc2vJ5m+XAE+aM9TQAAFhPlpQAAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdEhwAwBAhwQ3AAB0SHADAECHBDcAAHRIcAMAQIcENwAAdGjSWE9gonn8d7/Ldz7/P/Krn/8sL9jxRWsc95933pEtp07PAW89OX39/RtxhgAAjCeCey1VX19+fv+9Wfqjm3LnDT9Y87iqzJr7ilSff0QAAHg2U4Nrqary2r94b/onb5Kk1jQq/ZM3ycHvfG+q1jQGAIBnA8G9DrZ+/guy/wl/nqStYUTL/ie8PVtNf/7GnBYAAOOQ4F5H8/74kMze+RVPuYNdVZm987zM++ODx2hmAACMJ4J7Ha1+aYmlJAAAPJngXg9PXVpiKQkAAE82quCuqoOr6taquqOqTl3N89tX1eVVtaSqrqyqWSOe+1hV3dT7OHrE9qqqRVV1W1XdUlXvGbH9rN5rLamqXTfEiXZl5dKSJJaSAADwFE/7toBV1Z/k00kOSrI0yfVVdUlr7Ucjhn0yyRdba+dW1QFJzkxyfFW9PsmuSeYn2TTJVVX1jdbaQ0nekmR2kpe11h6vqpW3hQ9JslPvY48kn+19HpeqKge/6y/z3f/9pex11J9ZSgIAwJOM5g737knuaK3d2Vp7LMkFSRauMmZukst7j68Y8fzcJFe11oZaa48kWZxk5S3gdyY5vbX2eJK01n7a274ww/HeWmvfS7JNVW23Due20Ww17fk5+J3vzVbTLCUBAODJRhPcM5PcO+Lrpb1tIy1OckTv8ZuSbFlVU3vbD6mqKVU1LclrMnxXO0lelOToqhqsqm9U1U5r8XoAADAhjCa4V7dGYtU3oH5fkldX1Y1JXp3kviRDrbXLklya5LtJzk9yXZKh3j6bJlnRWhtI8j+TnLMWr5eqOqkX64PLli0bxWkAAMDGN5rgXprf35VOkllJ7h85oLV2f2vt8NbaK5N8sLdtee/zotba/NbaQRmO6dtHHPervccXJZk32tfrHffs1tpAa21g+vTpozgNAADY+EYT3Ncn2amqdqyqTZIck+SSkQOqalpVrTzWaendra6q/t7SklTVvAxH9WW9cRcnOaD3+NVJbus9viTJCb13K9kzyfLW2k/W6ewAAGCMPe27lLTWhqrqlCTfStKf5JzW2s1VdXqSwdbaJUn2T3JmVbUkVyd5d2/3yUmu6b1zx0NJjmutrVxS8tEk51XVXyZ5OMnbe9svTfK6JHckeTTJW9f7LAEAYIxUa09ZHj3hDAwMtMHBwbGeBgAAz3BVdUPvZxBHzW+aBACADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA4JbgAA6JDgBgCADgluAADokOAGAIAOCW4AAOiQ4AYAgA5Va22s57DeqmpZkrs7OPS0JD/r4Lh0w/WaWFyvicX1mlhcr4nF9ZpYXtpa23JtdpjU1Uw2ptba9C6OW1WDrbWBLo7Nhud6TSyu18Tiek0srtfE4npNLFU1uLb7WFICAAAdEtwAANAhwf2HnT3WE2CtuF4Ti+s1sbheE4vrNbG4XhPLWl+vZ8QPTQIAwHjlDjcAAHRIcCepqs2q6gdVtbiqbq6q/7u3fceq+n5V3V5VX66qTcZ6rvxeVfVX1Y1V9bXe167XOFVVd1XVv1XVD1f+dHdVPa+qvt27Xt+uqueO9TwZVlXbVNVXqurHVXVLVb3K9Rqfquqlve+rlR8PVdV7Xa/xq6r+stcaN1XV+b0G8efXOFVV/6V3rW6uqvf2tq3195fgHvabJAe01nZJMj/JwVW1Z5KPJflUa22nJL9I8udjOEee6r8kuWXE167X+Paa1tr8EW99dWqSy3vX6/Le14wP/0+Sb7bWXpZklwx/n7le41Br7dbe99X8JLsleTTJRXG9xqWqmpnkPUkGWmsvT9Kf5Jj482tcqqqXJ3lHkt0z/P+Fh1bVTlmH7y/BnaQNe7j35eTeR0tyQJKv9Lafm+SNYzA9VqOqZiV5fZK/731dcb0mmoUZvk6J6zVuVNVWSfZL8g9J0lp7rLX2y7heE8GBSf69tXZ3XK/xbFKSzatqUpIpSX4Sf36NV3OSfK+19mhrbSjJVUnelHX4/hLcPb3lCT9M8tMk307y70l+2fsPnCRLk8wcq/nxFH+b5ANJHu99PTWu13jWklxWVTdU1Um9bS9orf0kSXqfnz9ms2OkP0qyLMnne0u2/r6qnhPXayI4Jsn5vceu1zjUWrsvySeT3JPh0F6e5Ib482u8uinJflU1taqmJHldktlZh+8vwd3TWvtd75/kZmX4nw7mrG7Yxp0Vq1NVhyb5aWvthpGbVzPU9Ro/9m6t7ZrkkCTvrqr9xnpCrNGkJLsm+Wxr7ZVJHonlCONeb83vYUn+91jPhTXrrfVdmGTHJDOSPCfD/7+4Kn9+jQOttVsyvNzn20m+mWRxkqE/uNMaCO5V9P7p9MokeybZpvdPPslwiN8/VvPiSfZOclhV3ZXkggz/U9zfxvUat1pr9/c+/zTD60t3T/KfVbVdkvQ+/3TsZsgIS5Msba19v/f1VzIc4K7X+HZIkn9trf1n72vXa3z64yT/0Vpb1lr7bZILk+wVf36NW621f2it7dpa2y/Jz5PcnnX4/hLcSapqelVt03u8eYa/IW5JckWSI3vDTkzyT2MzQ0ZqrZ3WWpvVWtshw/+E+p3W2rFxvcalqnpOVW258nGSP8nwP9NdkuHrlLhe40Zr7YEk91bVS3ubDkzyo7he492b8/vlJInrNV7dk2TPqprS+9mjld9f/vwap6rq+b3PL0xyeIa/z9b6+8svvklSVfMyvOi9P8N/CflfrbXTq+qPMnwH9XlJbkxyXGvtN2M3U1ZVVfsneV9r7VDXa3zqXZeLel9OSvKl1v7/du7QJsIgCAPoN4YG8AgqoBmCvoQKrgeaoYdTV8B1gMGTnEYMYn9xmmRyv3hPrtpkszufmNn+qKrHJJ9JnrKK0Gt3/9xpm9yoqpesgeSHJF9JDtnexjiv3dl6S7+TPHf3dVtzv3Zq+3r4Las14ZLkPatnW/3aoao6Z82J/SY5dvfpP/dL4AYAgEFaSgAAYJDADQAAgwRuAAAYJHADAMAggRsAAAYJ3AAAMEjgBgCAQQI3AAAM+gNTkTriPTS7ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([28, 90, 0.9958, 0.9990])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
