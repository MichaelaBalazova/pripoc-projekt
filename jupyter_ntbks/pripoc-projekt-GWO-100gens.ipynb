{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 100, num_eval = 100):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 24 features - 1.0116876046419123\n",
      "2 . run = 34 features - 1.0035010624075984\n",
      "3 . run = 25 features - 1.0117366416530391\n",
      "4 . run = 35 features - 1.0029782581760065\n",
      "5 . run = 33 features - 1.004502067699816\n",
      "---------------------------------------\n",
      "BEST --> 25 FEATURES - fitness = 1.0117366416530391\n",
      "executed time = 1133.958976984024 sec\n",
      "---------------------------------------\n",
      "25 features, f1 = 0.9965016582353929\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=40))\n",
    "# opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=40), num_iter = 5, num_gen = 100, num_eval = 100)\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 26 features - 1.0077844255808293\n",
      "2 . run = 35 features - 1.0018960894135505\n",
      "3 . run = 35 features - 1.0016794987958961\n",
      "4 . run = 32 features - 1.0027373509141182\n",
      "5 . run = 35 features - 1.0012464725577606\n",
      "---------------------------------------\n",
      "BEST --> 26 FEATURES - fitness = 1.0077844255808293\n",
      "executed time = 1222.3557014465332 sec\n",
      "---------------------------------------\n",
      "26 features, f1 = 0.993877042156238\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 39 features - 1.0003994444612712\n",
      "2 . run = 35 features - 1.0025451225035868\n",
      "3 . run = 34 features - 1.0037177539743258\n",
      "4 . run = 36 features - 1.0018468547210468\n",
      "5 . run = 33 features - 1.0042855753925088\n",
      "---------------------------------------\n",
      "BEST --> 33 FEATURES - fitness = 1.0042855753925088\n",
      "executed time = 925.9665372371674 sec\n",
      "---------------------------------------\n",
      "33 features, f1 = 0.9975948572988306\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 27 features - 1.0084796854264046\n",
      "2 . run = 31 features - 1.0055730023973282\n",
      "3 . run = 29 features - 1.0077471659031811\n",
      "4 . run = 29 features - 1.007097705040506\n",
      "5 . run = 24 features - 1.0134194523026965\n",
      "---------------------------------------\n",
      "BEST --> 24 FEATURES - fitness = 1.0134194523026965\n",
      "executed time = 580.6206245422363 sec\n",
      "---------------------------------------\n",
      "24 features, f1 = 0.9967199854909392\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 35 features - 1.002545408349525\n",
      "2 . run = 29 features - 1.0038504909880308\n",
      "3 . run = 31 features - 1.004274414324797\n",
      "4 . run = 34 features - 1.0017690968652972\n",
      "5 . run = 33 features - 1.0016873173335625\n",
      "---------------------------------------\n",
      "BEST --> 31 FEATURES - fitness = 1.004274414324797\n",
      "executed time = 1136.989045381546 sec\n",
      "---------------------------------------\n",
      "31 features, f1 = 0.9958457753036399\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (25, 0.9965016582353929, 'gwo'),\n",
       " (26, 0.993877042156238, 'ga'),\n",
       " (33, 0.9975948572988306, 'fa'),\n",
       " (24, 0.9967199854909392, 'pso'),\n",
       " (31, 0.9958457753036399, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (33, 0.9975948572988306, 'fa'),\n",
       " (24, 0.9967199854909392, 'pso'),\n",
       " (25, 0.9965016582353929, 'gwo'),\n",
       " (31, 0.9958457753036399, 'ba'),\n",
       " (26, 0.993877042156238, 'ga')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([22, 90, 0.9935, 0.9985])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
