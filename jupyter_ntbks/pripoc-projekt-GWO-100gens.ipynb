{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 100, num_eval = 100):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 32 features - 1.0055518344120526\n",
      "2 . run = 31 features - 1.0057895780139727\n",
      "3 . run = 25 features - 1.0095723437177635\n",
      "4 . run = 27 features - 1.0099949309095668\n",
      "5 . run = 27 features - 1.010211565911363\n",
      "---------------------------------------\n",
      "BEST --> 27 FEATURES - fitness = 1.010211565911363\n",
      "executed time = 1865.3652317523956 sec\n",
      "---------------------------------------\n",
      "27 features, f1 = 0.9975949225442127\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=12))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 34 features - 1.0015526719540113\n",
      "2 . run = 38 features - 1.0009931766676539\n",
      "3 . run = 33 features - 1.0025537595004788\n",
      "4 . run = 34 features - 1.0030682585643111\n",
      "5 . run = 36 features - 1.0016301919956703\n",
      "---------------------------------------\n",
      "BEST --> 34 FEATURES - fitness = 1.0030682585643111\n",
      "executed time = 1959.2431192398071 sec\n",
      "---------------------------------------\n",
      "34 features, f1 = 0.9971574804274087\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 37 features - 1.0007529196511216\n",
      "2 . run = 37 features - 1.0016191848169331\n",
      "3 . run = 34 features - 1.0032845443488774\n",
      "4 . run = 35 features - 1.001679404178327\n",
      "5 . run = 37 features - 1.0016191256809523\n",
      "---------------------------------------\n",
      "BEST --> 34 FEATURES - fitness = 1.0032845443488774\n",
      "executed time = 1514.417534828186 sec\n",
      "---------------------------------------\n",
      "34 features, f1 = 0.9973759509168696\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 31 features - 1.0064390361366096\n",
      "2 . run = 27 features - 1.010427934489761\n",
      "3 . run = 26 features - 1.0103827008816237\n",
      "4 . run = 25 features - 1.0128188432195753\n",
      "5 . run = 29 features - 1.0077471659031811\n",
      "---------------------------------------\n",
      "BEST --> 25 FEATURES - fitness = 1.0128188432195753\n",
      "executed time = 1159.7337341308594 sec\n",
      "---------------------------------------\n",
      "25 features, f1 = 0.9975947911308842\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 32 features - 1.0025210787632588\n",
      "2 . run = 32 features - 1.0049023383169744\n",
      "3 . run = 25 features - 1.0128188432195753\n",
      "4 . run = 35 features - 1.002328840182489\n",
      "5 . run = 40 features - 1.000484718412457\n",
      "---------------------------------------\n",
      "BEST --> 25 FEATURES - fitness = 1.0128188432195753\n",
      "executed time = 1216.1844747066498 sec\n",
      "---------------------------------------\n",
      "25 features, f1 = 0.9975947911308842\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (27, 0.9975949225442127, 'gwo'),\n",
       " (34, 0.9971574804274087, 'ga'),\n",
       " (34, 0.9973759509168696, 'fa'),\n",
       " (25, 0.9975947911308842, 'pso'),\n",
       " (25, 0.9975947911308842, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (27, 0.9975949225442127, 'gwo'),\n",
       " (25, 0.9975947911308842, 'pso'),\n",
       " (25, 0.9975947911308842, 'ba'),\n",
       " (34, 0.9973759509168696, 'fa'),\n",
       " (34, 0.9971574804274087, 'ga')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([22, 90, 0.9969, 0.9985])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
