{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 75, num_eval = 75):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 36 features - 1.0022799037833345\n",
      "2 . run = 35 features - 1.0021123357988933\n",
      "3 . run = 27 features - 1.0076136713558512\n",
      "4 . run = 32 features - 1.0059848012028538\n",
      "5 . run = 28 features - 1.0088311226352393\n",
      "---------------------------------------\n",
      "BEST --> 28 FEATURES - fitness = 1.0088311226352393\n",
      "executed time = 449.6536719799042 sec\n",
      "---------------------------------------\n",
      "28 features, f1 = 0.9973763143501697\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=12))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 37 features - 1.001186122100758\n",
      "2 . run = 36 features - 1.002712765270964\n",
      "3 . run = 36 features - 1.002712765270964\n",
      "4 . run = 36 features - 1.0016302715715037\n",
      "5 . run = 35 features - 1.0021122518459937\n",
      "---------------------------------------\n",
      "BEST --> 36 FEATURES - fitness = 1.002712765270964\n",
      "executed time = 528.3436484336853 sec\n",
      "---------------------------------------\n",
      "36 features, f1 = 0.9982508291176966\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 34 features - 1.0028518315972126\n",
      "2 . run = 38 features - 1.0022919831904187\n",
      "3 . run = 39 features - 0.999966722741532\n",
      "4 . run = 34 features - 1.0024189945942155\n",
      "5 . run = 37 features - 1.0009697668234157\n",
      "---------------------------------------\n",
      "BEST --> 34 FEATURES - fitness = 1.0028518315972126\n",
      "executed time = 522.994886636734 sec\n",
      "---------------------------------------\n",
      "34 features, f1 = 0.9969388673293293\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 24 features - 1.0134196346933604\n",
      "2 . run = 27 features - 1.0095619021801103\n",
      "3 . run = 25 features - 1.012602551206668\n",
      "4 . run = 32 features - 1.0042528774542991\n",
      "5 . run = 26 features - 1.0093001822821728\n",
      "---------------------------------------\n",
      "BEST --> 24 FEATURES - fitness = 1.0134196346933604\n",
      "executed time = 472.8686010837555 sec\n",
      "---------------------------------------\n",
      "24 features, f1 = 0.9967201697239331\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 33 features - 1.003419544120966\n",
      "2 . run = 37 features - 1.0016190657145956\n",
      "3 . run = 33 features - 1.0038526497062985\n",
      "4 . run = 33 features - 1.0032030204809728\n",
      "5 . run = 32 features - 1.0025210787632588\n",
      "---------------------------------------\n",
      "BEST --> 33 FEATURES - fitness = 1.0038526497062985\n",
      "executed time = 508.68726444244385 sec\n",
      "---------------------------------------\n",
      "33 features, f1 = 0.9971575586258907\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (28, 0.9973763143501697, 'gwo'),\n",
       " (36, 0.9982508291176966, 'ga'),\n",
       " (34, 0.9969388673293293, 'fa'),\n",
       " (24, 0.9967201697239331, 'pso'),\n",
       " (33, 0.9971575586258907, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (36, 0.9982508291176966, 'ga'),\n",
       " (28, 0.9973763143501697, 'gwo'),\n",
       " (33, 0.9971575586258907, 'ba'),\n",
       " (34, 0.9969388673293293, 'fa'),\n",
       " (24, 0.9967201697239331, 'pso')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAJCCAYAAACF/6LRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde5TWZb3//+d7hpMkogJ5AFR26g7MEXEAEw+oUVgqHlNT1ErpoKtVe2lf3Np395NNaLV23/yl7c33uy1reWh/t4f4pZZFHjApGbdCoKlsQkVyh4cNqZGOvn9/zGfqbpyBGwa5mPH5WOte87mvz3V9Ptc1spYvLt73547MRJIkSdLW1VB6ApIkSdI7kUFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpALqCuIRMTUiHo+I5RExs5Pze0bE/IhYEhH3RMSImnNXRsTS6nVaTfvREfEfEfFIRNwfEXtX7edGxJqq/ZGIOK9mzDkR8WT1Oqd7S5ckSZLKiY09RzwiGoEngCnAKmARcEZmPlrT5/8CP8rM6yLiKODjmTk9Ij4CfB44BugP3AsclZnrIuIJYFpmPhYRnwUmZOa5EXEu0JyZF3aYx85AC9AMJPAQcFBmvtT9X4MkSZK0ddWzIz4BWJ6ZKzLzNeAmYFqHPmOA+dXx3TXnxwD3ZmZrZr4CLAamVucS2KE6Hgys3sg8PgT8NDNfrML3T2uuJUmSJPUoferoMxx4pub9KmBihz6LgZOBbwInAoMiYkjV/g8R8U/AQOBIoH0n/Tzgjoj4I7AOOLjmeidHxOG07cR/ITOf6WIewzubcETMAGYAvOtd7zrove99bx3LlCRJkjbPQw899HxmDtuUMfUE8eikrWM9y0XAt6qykvuAZ4HWzLwrIsYDDwBrgIVAazXmC8CHM/NXEXEx8E+0hfP/D7gxM/8UEZ8GrgOOqnMebY2Zc4G5AM3NzdnS0lLHMiVJkqTNExFPbeqYekpTVgEja96PoEMZSWauzsyTMvNA4NKqbW31c3Zmjs3MKbSF6ScjYhhwQGb+qrrED4BDqv4vZOafqvb/DRxU7zwkSZKknqKeIL4I2CciRkVEP+B0YF5th4gYGhHt17oEuLZqb6xKVIiIJqAJuAt4CRgcEftWY6YAj1X9dqu59PHt7cBPgA9GxE4RsRPwwapNkiRJ6nE2WpqSma0RcSFtobcRuDYzl0XE5UBLZs4DJgNzIiJpK025oBreF1gQEdBWB35WZrYCRMT5wM0R8SZtwfwT1ZjPRcTxtJWwvAicW83jxYiYRdtfDAAuz8wXu7N4SZIkqZSNPr6wp+usRvz1119n1apVrF+/vtCs3j4DBgxgxIgR9O3bt/RUJEmS3jEi4qHMbN6UMfV8WLPXWbVqFYMGDWKvvfai2q3vFTKTF154gVWrVjFq1KjS05EkSdIGvCO/4n79+vUMGTKkV4VwgIhgyJAhvXKnX5Ikqbd5RwZxoNeF8Ha9dV2SJEm9zTs2iEuSJEklGcS3IXvttRfPP/88ANtvv33h2UiSJOntZBCXJEmSCjCIF3LCCSdw0EEHsd9++zF37tzS05EkSdJW9o58fOG24Nprr2XnnXfmj3/8I+PHj+fkk08uPSVJkiRtRQbxQq666ipuvfVWAJ555hmefPLJwjOSJEnS1mQQ70TrG2/y5XnL+N3a9bxv+OAu+y19di27DR7Al4/fjz6N9Vf53HPPPfzsZz9j4cKFDBw4kMmTJ/vsb0mSpHcYg3gnGhuC/1zzCr/67QvM/83vu+zXEHDw3wyhsWHTnt29du1adtppJwYOHMhvfvMbfvnLX3Z3ypIkSeph/LBmJyKCr57SRP8+jXQVsQPo36eRr57StMlfojN16lRaW1tpamriS1/6EgcffHC35yxJkqSexR3xLozceSCXfmQ0l922tNPzCVx27GhG7DRwk6/dv39/7rzzzre0r1y58s/HL7/88iZfV5IkST2HO+IbcObEPXj/3wyhY+VJQ8Ah7xnCxybsUWZikiRJ6vEM4hvQWYlKd0pSJEmSpHYG8Y1oL1HJ6n13SlIkSZKkdgbxOrSXqIAlKZIkSdoyDOJ1iAi+/tEDOPWgEXzt1AMsSZEkSVK3+dSUOg3fcTu+duoBpachSZKkXsIdcUmSJKkAg7gkSZJUgKUphcyaNYvrr7+ekSNHMnToUA466CAGDx7M3Llzee2119h77735/ve/z8CBPp1FkiSpN3JHvICWlhZuvvlmHn74YW655RZaWloAOOmkk1i0aBGLFy9m9OjR/Ou//mvhmUqSJOnt4o54Affffz/Tpk1ju+22A+C4444DYOnSpVx22WX893//Ny+//DIf+tCHSk5TkiRJbyODeGfeaIU7vwjrVsNuG3hSyu8egR2GwzFfhcb6f5WZ2Wn7ueeey2233cYBBxzAd7/7Xe65555NnLgkSZJ6CoN4Zxoa4fkn4KlfwBN3dt0vGmCvQ9v6b4JDDz2UT33qU1xyySW0trZy++23c/755/OHP/yB3Xbbjddff53rr7+e4cOHd3MhkiRJ2lYZxDsTAdOuhmsmwuvrgc52sAP69G/rt4lf8DN+/HiOP/54DjjgAPbcc0+am5sZPHgws2bNYuLEiey5557sv//+/OEPf9giy5EkSdK2J7oqk+gtmpubs/3DkO0ee+wxRo8evfHBi/4Vbv+7rs8f+w1o/sRmzevll19m++2359VXX+Xwww9n7ty5jBs3brOu1VHd65MkSdIWEREPZWbzpozxqSkb0vwJ2OuwthKUWtEAow6Hgz6+2ZeeMWMGY8eOZdy4cZx88slbLIRLkiSpZ7A0ZUM6LVHZ/JKUWjfccMMWm6YkSZJ6HnfEN2anPeGDs/lLnXjCh74CO+5RclaSJEnq4Qzi9WgvUYFul6RIkiRJYBCvTwSc8G0YexZMu6ZbJSmSJEkSWCNevx1HwglXl56FJEmSegl3xCVJkqQCDOKSJElSAQbxQmbNmsV73/tepkyZwhlnnMFXv/pVDjroIAAWL15MRPD0008D8J73vIdXX32Vp556iqOPPpqmpiaOPvroP5+XJElSz2MQL6ClpYWbb76Zhx9+mFtuuYWWlhYaGhpYv34969atY8GCBTQ3N7NgwQKeeuop3v3udzNw4EAuvPBCzj77bJYsWcKZZ57J5z73udJLkSRJ0mbyw5oF3H///UybNo3tttsOgOOOOw6AQw45hF/84hfcd999/P3f/z0//vGPyUwOO6zt0YkLFy7klltuAWD69Ol88YtfLLMASZIkdZtBvBOtb7ZyxYNX8NwrzzFmyJgu+z36wqPs+q5dmTlhJn0a6v9VZman7Ycddtifd8GnTZvGlVdeSURw7LHHdto/fIyiJElSj2UQ70RjNLJi7Qpanmvh3lX3dtmvgQaad22mMRo36fqHHnoon/rUp7jkkktobW3l9ttv5/zzz+fwww/nsssu4/DDD6ehoYGdd96ZO+64gzlz5gBtO+Y33XQT06dP5/rrr+fQQw/t1jolSZJUjjXinYgIZk2aRf/G/gSd7zoHQb/GfsyaNGuTd6bHjx/P8ccfzwEHHMBJJ51Ec3MzgwcPZq+99gLg8MMPB9oC+4477shOO+0EwFVXXcV3vvMdmpqa+P73v883v/nNzV+kJEmSioquyiR6i+bm5mxpafmrtscee4zRo0dvdOy/Pf5vzPrlrC7Pf+ngL/HRv/3oZs3r5ZdfZvvtt+fVV1/l8MMPZ+7cuYwbN26zrtVRveuTJEnSlhERD2Vm86aMcUd8A07d91TG7zr+LbviDTQwYdcJnLrvqZt97RkzZjB27FjGjRvHySefvMVCuCRJknoGa8Q3oL1E5YTbTuBPb/yJJLtVklLrhhtu2IIzlSRJUk/jjvhGDN9+OBePv5ikrYQnSS4efzG7b7974ZlJkiSpJzOI16G9RAXodkmKJEmSBAbxukQEsyfN5oS9T+AfJ/2jz++WJElSt1kjXqfdtt+NWZO6foKKJEmStCncES9g5cqVvO997ys9DUmSJBVkEJckSZIKMIgX0trayjnnnENTUxOnnHIKr776Kpdffjnjx4/nfe97HzNmzKC3f9mSJEnSO5lBvJDHH3+cGTNmsGTJEnbYYQeuueYaLrzwQhYtWsTSpUv54x//yI9+9KPS05QkSdLbxCBeyMiRI5k0aRIAZ511Fvfffz933303EydOZP/99+fnP/85y5YtKzxLSZIkvV18akonsrWV52bPpvW5/2LAmDFd9lu/bBl9dtuVXS+9lOizab/Kjo9AjAg++9nP0tLSwsiRI/nyl7/M+vXrN2v+kiRJ2vYZxDvT2MhrK1bw6qIWXr777q77NTQwcPx4aGzc5Fs8/fTTLFy4kPe///3ceOONHHrooTzwwAMMHTqUl19+mX//93/nlFNO6cYiJEmStC2zNKUTEcFus79C9OsHXX15TwTRrx+7f2X2Zn3Bz+jRo7nuuutoamrixRdf5DOf+Qznn38++++/PyeccALjx4/v5iokSZK0LYve/mSO5ubmbGlp+au2xx57jNGjR2907Es33cRzX/5/ujy/65e/zE6nn9btOW5p9a5PkiRJW0ZEPJSZzZsyxh3xDdjxtNMYOHECNHT4NTU0MHDiRHY87aNlJiZJkqQer64gHhFTI+LxiFgeETM7Ob9nRMyPiCURcU9EjKg5d2VELK1ep9W0Hx0R/xERj0TE/RGxd9X+dxHxaHWt+RGxZ82YN6r+j0TEvO4tva51v7VEpZslKZIkSRLUEcQjohG4GjgGGAOcEREdHyXydeB7mdkEXA7MqcZ+BBgHjAUmAhdHxA7VmG8DZ2bmWOAG4LKq/WGgubrWvwNfrbnPHzNzbPU6fpNXuxn6jRjOLjP/B7SX8GSyy8yZ9B0+fGvcXpIkSb1UPTviE4DlmbkiM18DbgKmdegzBphfHd9dc34McG9mtmbmK8BiYGp1LoH2UD4YWA2QmXdn5qtV+y+BP++ul/LnEhWwJEWSJElbRD2PLxwOPFPzfhVtu9u1FgMnA98ETgQGRcSQqv0fIuKfgIHAkcCj1ZjzgDsi4o/AOuDgTu79SeDOmvcDIqIFaAWuyMzbOptwRMwAZgDssccedSxxwyKC3efMYc23rmbYhRdYktJbvdEKd34R1q2G3Q7out/vHoEdhsMxX4VGnwAqSdK2rvWNN/nyvGX8bu163jd8cJf9lj67lt0GD+DLx+9Hn8a3/6OU9aSIzlJnx0etXAR8KyLOBe4DngVaM/OuiBgPPACsARbSFqIBvgB8ODN/FREXA/9EWzhvu2nEWUAzcETNffbIzNUR8TfAzyPi15n5n2+ZXOZcYC60PTWljjVuVN/dd2f3r8zeEpfStqqhEZ5/Ap76BTxxZ9f9ogH2OrStvyRJ2uY1NgT/ueYVfvXbF5j/m9932a8h4OC/GUJjw9bZdK0n6q8CRta8H0FVRtIuM1dn5kmZeSBwadW2tvo5u6rpnkJbqH8yIoYBB2Tmr6pL/AA4pP16EfGB6jrHZ+afau9T/VwB3AMcuAlr3aZcddVVjB49mjPPPLP0VNQuAqZdDX360/nfP2lr79O/rZ//MiJJUo8QEXz1lCb692nc0P/h6d+nka+e0rTVqh/qCeKLgH0iYlRE9ANOB/7qiSURMTQi2q91CXBt1d5YlagQEU1AE3AX8BIwOCL2rcZMAR6r+h0I/AttIfz3NffYKSL6t98PmMRfylx6nGuuuYY77riD66+/vvRUVGunPeGDs3nrP/q0S/jQV2DH7pc8SZKkrWfkzgO59COjN/R/eC47djQjdhq41ea00SCema3AhcBPaAvL/5aZyyLi8ohof3LJZODxiHgC2AVor+HoCyyIiEdpKxU5q/rgZitwPnBzRCwGpgMXV2O+BmwP/N8OjykcDbRU/e+mrUa8RwbxT3/606xYsYLjjz+eK6+8kkMOOYQDDzyQQw45hMcff7z09NT8CdjrsLYSlFrRAKMOh4M+XmZekiSpW86cuAfv/5shdKw8aQg45D1D+NiErbvR5jdrFrLXXnvR0tJCv379GDhwIH369OFnP/sZ3/72t7n55pu7de1tYX093ktPwTUT4fX1tP0dOaDvALjgQXfDJUnqwZ558VU++I37WP/6G+3/h2dA30Z++neHd2s3fHO+WdNHPhS2du1azjnnHJ588kkigtdff730lAR/KVG5/e+qBktSJEnqDdpLVC67bSlQpiSlnUG8E2++8SYLfvAkL7+0nmF7DOqy35qn/8D2Ow3gsNP2oWEzH3HzpS99iSOPPJJbb72VlStXMnny5M2ctba45k/Aslth5QJLUiRJ6kXOnLgHty/5HQtXvFCkJKWdQbwT0RC89NwrPPvkf7Py1y903S9g9313JLrxiJu1a9cyvPqWzu9+97ubfR29DSLghG/DPVfA5Jk+JUWSpF4iIvj6Rw/gf/30CT4/Zd9i3xHz9j+pvAeKCI46ezR9+m7419PYt4Gjzh7drf94X/ziF7nkkkuYNGkSb7zxxmZfR2+THUfCCVe3/ZQkSb3G8B2342unHsDwHbcrNgd3xLuww9DtmHTKPtx7Q9dPMZl0yj7sMGTz/uOtXLkSgKFDh/LEE0/8uX3WrFmbdT1JkiT1LO6Ib8B+h+3O8H13fMt3u0TA8L/dkf0O273MxCRJktTjGcQ3oKsSlS1RkiJJkqR3NoP4RrSXqNTqTkmKJEmSBAbxuvy5RAVLUiRJkrRl+GHNOkQER587hgd/9FsmHDvKkhRJkiR1m0G8ToN2HsDRZ/u18ZIkSdoyLE2RJEmSCjCIS5IkSQUYxAtYuXIl733veznnnHNoamrilFNO4dVXX2XmzJmMGTOGpqYmLrroIgCeeuopjj76aJqamjj66KN5+umnC89ekiRJW4JBvJDHH3+cGTNmsGTJEnbYYQe+9a1vceutt7Js2TKWLFnCZZddBsCFF17I2WefzZIlSzjzzDP53Oc+V3jmkiRJ2hIM4oWMHDmSSZMmAXDWWWdx3333MWDAAM477zxuueUWBg4cCMDChQv52Mc+BsD06dO5//77i81ZkiRJW45PTenEm2+8wc+/8y/84cXn2WXUe7rs918rljNoyDCO+vinaGhs3KR7dHwEYt++fXnwwQeZP38+N910E9/61rf4+c9/vtFxkiRJ6pkM4p2IhgZeXP0Mqx5dyoqHHuy6XwQjxuxPNGz6Pyw8/fTTLFy4kPe///3ceOONjB07lrVr1/LhD3+Ygw8+mL333huAQw45hJtuuonp06dz/fXXc+ihh272uiRJkrTtsDSlExHBhz79eRr79gO62oEOGvv2Y+pnPr9Zu9SjR4/muuuuo6mpiRdffJHzzjuPY489lqamJo444gi+8Y1vAHDVVVfxne98h6amJr7//e/zzW9+c/MXJkmSpG2GO+JdGPzuXZh89if52f+5poseyeSzz2OHYe/erOs3NDTwz//8z3/V9uCDb91932uvvTotUZEkSVLP5o74BjR94BhG7rf/W3a8I4KR+zXR9IGphWYmSZKkns4gvgGdl6h0ryQF2na5ly5dusXmKUmSpJ7nHRvEM7Oufu0lKtDev3slKW+3etclSZKkst6RQXzAgAG88MILdYfW9hIVYJsuSclMXnjhBQYMGFB6KpIkSdqId+SHNUeMGMGqVatYs2ZN3WP2nnIc2XcAe0+ewm9+85u3cXbdM2DAAEaMGFF6GpIkSdqId2QQ79u3L6NGjdrkcePef8jbMBtJkiS9E70jS1MkSZKk0gzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpALqCuIRMTUiHo+I5RExs5Pze0bE/IhYEhH3RMSImnNXRsTS6nVaTfvREfEfEfFIRNwfEXtX7f0j4gfVvX4VEXvVjLmkan88Ij7UnYVLkiRJJW00iEdEI3A1cAwwBjgjIsZ06PZ14HuZ2QRcDsypxn4EGAeMBSYCF0fEDtWYbwNnZuZY4Abgsqr9k8BLmbk38A3gyupaY4DTgf2AqcA11dwkSZKkHqeeHfEJwPLMXJGZrwE3AdM69BkDzK+O7645Pwa4NzNbM/MVYDFtIRoggfZQPhhYXR1PA66rjv8dODoiomq/KTP/lJm/BZZXc5MkSZJ6nHqC+HDgmZr3q6q2WouBk6vjE4FBETGkaj8mIgZGxFDgSGBk1e884I6IWAVMB67oeL/MbAXWAkPqnAcAETEjIloiomXNmjV1LFGSJEnauuoJ4tFJW3Z4fxFwREQ8DBwBPAu0ZuZdwB3AA8CNwEKgtRrzBeDDmTkC+A7wTxu5Xz3zaGvMnJuZzZnZPGzYsC4XJkmSJJVSTxBfxV92sQFG8JcyEgAyc3VmnpSZBwKXVm1rq5+zM3NsZk6hLUw/GRHDgAMy81fVJX4AHNLxfhHRh7aylRfrmYckSZLUU9QTxBcB+0TEqIjoR9sHJufVdoiIoRHRfq1LgGur9saqRIWIaAKagLuAl4DBEbFvNWYK8Fh1PA84pzo+Bfh5ZmbVfnr1VJVRwD7Ag5u6YEmSJGlb0GdjHTKzNSIuBH4CNALXZuayiLgcaMnMecBkYE5EJHAfcEE1vC+woO2zlqwDzqrqvomI84GbI+JN2oL5J6ox/wp8PyKW07YTfno1j2UR8W/Ao7SVt1yQmW909xcgSZIklRBtm829V3Nzc7a0tJSehiRJknqxiHgoM5s3ZYzfrClJkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkF1BXEI2JqRDweEcsjYmYn5/eMiPkRsSQi7omIETXnroyIpdXrtJr2BRHxSPVaHRG3Ve0X17QvjYg3ImLn6tzKiPh1da6l+8uXJEmSyuizsQ4R0QhcDUwBVgGLImJeZj5a0+3rwPcy87qIOAqYA0yPiI8A44CxQH/g3oi4MzPXZeZhNfe4GfghQGZ+Dfha1X4c8IXMfLHmXkdm5vObv2RJkiSpvHp2xCcAyzNzRWa+BtwETOvQZwwwvzq+u+b8GODezGzNzFeAxcDU2oERMQg4Critk3ufAdxYz0IkSZKknqSeID4ceKbm/aqqrdZi4OTq+ERgUEQMqdqPiYiBETEUOBIY2WHsicD8zFxX2xgRA2kL7TfXNCdwV0Q8FBEzuppwRMyIiJaIaFmzZk0dS5QkSZK2rnqCeHTSlh3eXwQcEREPA0cAzwKtmXkXcAfwAG072wuB1g5ju9r1Pg74RYeylEmZOQ44BrggIg7vbMKZOTczmzOzediwYRtenSRJklRAPUF8FX+9iz0CWF3bITNXZ+ZJmXkgcGnVtrb6OTszx2bmFNpC/ZPt46pd8wnA7Z3c93Q6BPTMXF39/D1wazVWkiRJ6nHqCeKLgH0iYlRE9KMtIM+r7RARQyOi/VqXANdW7Y1V2CYimoAm4K6aoacCP8rM9R2uN5i2nfUf1rS9q6onJyLeBXwQWFrvQiVJkqRtyUafmpKZrRFxIfAToBG4NjOXRcTlQEtmzgMmA3MiIoH7gAuq4X2BBREBsA44KzNrS1NOB67o5LYnAndVH/Bstwtwa3WtPsANmfnjulcqSZIkbUMis2O5d+/S3NycLS0+clySJElvn4h4KDObN2WM36wpSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBdQVxCNiakQ8HhHLI2JmJ+f3jIj5EbEkIu6JiBE1566MiKXV67Sa9gUR8Uj1Wh0Rt1XtkyNibc25/1nvPCRJkqSeos/GOkREI3A1MAVYBSyKiHmZ+WhNt68D38vM6yLiKGAOMD0iPgKMA8YC/YF7I+LOzFyXmYfV3ONm4Ic111uQmcduxjwkSZKkHqGeHfEJwPLMXJGZrwE3AdM69BkDzK+O773aLv4AABmnSURBVK45Pwa4NzNbM/MVYDEwtXZgRAwCjgJu2wLzkCRJknqEeoL4cOCZmverqrZai4GTq+MTgUERMaRqPyYiBkbEUOBIYGSHsScC8zNzXU3b+yNicUTcGRH7bcI8AIiIGRHREhEta9asqWOJkiRJ0tZVTxCPTtqyw/uLgCMi4mHgCOBZoDUz7wLuAB4AbgQWAq0dxp5RnWv3H8CemXkA8P/yl53yeubR1pg5NzObM7N52LBhXS5MkiRJKqWeIL6Kv97FHgGsru2Qmasz86TMPBC4tGpbW/2cnZljM3MKbWH6yfZx1a75BOD2mmuty8yXq+M7gL7VbvpG5yFJkiT1FPUE8UXAPhExKiL6AacD82o7RMTQiGi/1iXAtVV7YxW2iYgmoAm4q2boqcCPMnN9zbV2jYiojidUc3yhnnlIkiRJPcVGn5qSma0RcSHwE6ARuDYzl0XE5UBLZs4DJgNzIiKB+4ALquF9gQVVrl4HnJWZtaUppwNXdLjlKcBnIqIV+CNwemYm0Ok8NmfRkiRJUmnRlnF7r+bm5mxpaSk9DUmSJPViEfFQZjZvyhi/WVOSJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkF9Ck9Ab09Wt9s5YoHr+C5V55jzJAxXfZ79IVH2fVduzJzwkz6NPjHQZIkaWsxefVSjdHIirUraHmuhXtX3dtlvwYaaN61mcZo3IqzkyRJkqUpvVREMGvSLPo39ieIzvsQ9Gvsx6xJs4jovI8kSZLeHgbxXmz49sO5ePzFJNnp+SS5ePzF7L797lt5ZpIkSTKI93Kn7nsq43cd/5Zd8QYamLDrBE7d99RCM5MkSXpnM4j3cp2VqFiSIkmSVJ5B/B2gY4mKJSmSJEnlGcTfIdpLVABLUiRJkrYBBvF3iIhg9qTZnLD3CfzjpH+0JEWSJKkwnyP+DrLb9rsxa9Ks0tOQJEkS7ohLkiRJRRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUQF1BPCKmRsTjEbE8ImZ2cn7PiJgfEUsi4p6IGFFz7sqIWFq9TqtpXxARj1Sv1RFxW9V+ZnWdJRHxQEQcUDNmZUT8uhrT0r2lS5IkSeX02ViHiGgErgamAKuARRExLzMfren2deB7mXldRBwFzAGmR8RHgHHAWKA/cG9E3JmZ6zLzsJp73Az8sHr7W+CIzHwpIo4B5gITa+51ZGY+v7kLliRJkrYF9eyITwCWZ+aKzHwNuAmY1qHPGGB+dXx3zfkxwL2Z2ZqZrwCLgam1AyNiEHAUcBtAZj6QmS9Vp38JjECSJEnqZeoJ4sOBZ2rer6raai0GTq6OTwQGRcSQqv2YiBgYEUOBI4GRHcaeCMzPzHWd3PuTwJ017xO4KyIeiogZXU04ImZEREtEtKxZs2Yjy5MkSZK2vo2WpgDRSVt2eH8R8K2IOBe4D3gWaM3MuyJiPPAAsAZYCLR2GHsG8H/ectOII2kL4ofWNE/KzNUR8W7gpxHxm8y87y2Ty5xLW0kLzc3NHecqSZIkFVfPjvgq/noXewSwurZDZq7OzJMy80Dg0qptbfVzdmaOzcwptIX6J9vHVbvmE4Dba68XEU20hfNpmflC7X2qn78Hbq3GSpIkST1OPUF8EbBPRIyKiH7A6cC82g4RMTQi2q91CXBt1d5Yhe32cN0E3FUz9FTgR5m5vuZaewC3ANMz84ma9ndV9eRExLuADwJLN2WxkiRJ0rZio6UpmdkaERcCPwEagWszc1lEXA60ZOY8YDIwJyKSttKUC6rhfYEFEQGwDjgrM2tLU04Hruhwy/8JDAGuqca1ZmYzsAtwa9XWB7ghM3+86UuWJEmSyovM3l1C3dzcnC0tPnJckiRJb5+IeKjaPK6b36wpSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQX0KT0BqTPZ2spzs2fT+tx/MWDMmC77rV+2jD677cqul15K9PGPsyRJ6jlMLto2NTby2ooVvLqohZfvvrvrfg0NDBw/Hhobt97cJEmStgBLU7RNigh2m/0Vol8/iOiqE9GvH7t/ZTbRVR9JkqRtlEFc26x+I4azy8z/AZmdd8hkl5kz6Tt8+NadmCRJ0hZgENc2bcfTTmPgxAnQ0OGPakMDAydOZMfTPlpmYpIkSd1kENc2rdMSFUtSJElSL2AQ1zbvLSUqlqRIkqRewCCuHuHPJSpgSYokSeoVDOLqESKC3efMYfBJJ7H7nK9YkiJJkno8nyOuHqPv7ruz+1dml56GJEnSFuGOuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAuoK4hExNSIej4jlETGzk/N7RsT8iFgSEfdExIiac1dGxNLqdVpN+4KIeKR6rY6I26r2iIirqnstiYhxNWPOiYgnq9c53Vu6JEmSVE6fjXWIiEbgamAKsApYFBHzMvPRmm5fB76XmddFxFHAHGB6RHwEGAeMBfoD90bEnZm5LjMPq7nHzcAPq7fHAPtUr4nAt4GJEbEz8A9AM5DAQ9U8XurG+iVJkqQi6tkRnwAsz8wVmfkacBMwrUOfMcD86vjumvNjgHszszUzXwEWA1NrB0bEIOAo4LaqaRptoT4z85fAjhGxG/Ah4KeZ+WIVvn/a8VqSJElST1FPEB8OPFPzflXVVmsxcHJ1fCIwKCKGVO3HRMTAiBgKHAmM7DD2RGB+Zq7byP3qmQcAETEjIloiomXNmjV1LFGSJEnauuoJ4tFJW3Z4fxFwREQ8DBwBPAu0ZuZdwB3AA8CNwEKgtcPYM6pzG7tfPfNoa8ycm5nNmdk8bNiwzrpIkiRJRdUTxFfx17vYI4DVtR0yc3VmnpSZBwKXVm1rq5+zM3NsZk6hLUw/2T6u2jWfANxex/02Og9JkiSpp6gniC8C9omIURHRDzgdmFfbISKGRkT7tS4Brq3aG6uwTUQ0AU3AXTVDTwV+lJnra9rmAWdXT085GFibmb8DfgJ8MCJ2ioidgA9WbZIkSVKPs9GnpmRma0RcSFvobQSuzcxlEXE50JKZ84DJwJyISOA+4IJqeF9gQUQArAPOysza0pTTgSs63PIO4MPAcuBV4OPVPF6MiFm0/cUA4PLMfHET1ytJkiRtEyKz0zLrXqO5uTlbWlpKT0OSJEm9WEQ8lJnNmzLGb9aUJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAvqUnoDUHW++8SYLfvAkL7+0nmF7DOqy35qn/8D2Ow3gsNP2oaHRv39KkqTyDOLq0aIheOm5V3j2yf9m5a9f6LpfwO777kg0xFacnSRJUtfcGlSPFhEcdfZo+vTd8B/lxr4NHHX2aCIM4pIkadtgEFePt8PQ7Zh0yj4b7DPplH3YYch2W2lGkiRJG2cQV6+w32G7M3zfHaHDhncEDP/bHdnvsN3LTEySJKkLBnH1Cl2VqFiSIkmStlUGcfUanZWoWJIiSZK2VQZx9Sp/LlHBkhRJkrRt8/GF6lUigqPPHcODP/otE44dZUmKJEnaZhnE1esM2nkAR589uvQ0JEmSNsjSFEmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQXUFcQjYmpEPB4RyyNiZifn94yI+RGxJCLuiYgRNeeujIil1eu0mvaIiNkR8UREPBYRn6vaL46IR6rX0oh4IyJ2rs6tjIhfV+daur98SZIkqYw+G+sQEY3A1cAUYBWwKCLmZeajNd2+DnwvM6+LiKOAOcD0iPgIMA4YC/QH7o2IOzNzHXAuMBJ4b2a+GRHvBsjMrwFfq+59HPCFzHyx5l5HZubz3Vq1JEmSVFg9O+ITgOWZuSIzXwNuAqZ16DMGmF8d311zfgxwb2a2ZuYrwGJganXuM8DlmfkmQGb+vpN7nwHcWO9iJEmSpJ6iniA+HHim5v2qqq3WYuDk6vhEYFBEDKnaj4mIgRExFDiStl1wgPcAp0VES0TcGRH71F4wIgbSFtpvrmlO4K6IeCgiZnQ14YiYUV23Zc2aNXUsUZIkSdq66gni0Ulbdnh/EXBERDwMHAE8C7Rm5l3AHcADtO1sLwRaqzH9gfWZ2Qz8b+DaDtc8DvhFh7KUSZk5DjgGuCAiDu9swpk5NzObM7N52LBhdSxRkiRJ2rrqCeKr+MsuNsAIYHVth8xcnZknZeaBwKVV29rq5+zMHJuZU2gL9U/WXLd9t/tWoKnDfU+nQ1lKZq6ufv6+GjOhjvlLkiRJ25x6gvgiYJ+IGBUR/WgLyPNqO0TE0Ihov9YlVLvbEdFYlagQEU20he27qn63AUdVx0cAT9Rcb3DV9sOatndFxKD2Y+CDwNL6lypJkiRtOzb61JTMbI2IC4GfAI3AtZm5LCIuB1oycx4wGZgTEQncB1xQDe8LLIgIgHXAWZnZXppyBXB9RHwBeBk4r+a2JwJ3VR/wbLcLcGt1rT7ADZn5481YsyRJklRcZHYs9+5dmpubs6XFR45LkiTp7RMRD1Wffayb36wpSZIkFWAQlyRJkgrYaI24uvbmG2/w8+/8C3948Xl2GfWeLvv914rlDBoyjKM+/ikaGhu34gwlSZK0rTKId0M0NPDi6mdY9ehSVjz0YNf9IhgxZn+iwX+AkCRJUhuTYTdEBB/69Odp7NuPzr/3CCBo7NuPqZ/5PNUTXyRJkiSDeHcNfvcuTD77k7z1y0bbJZPPPo8dhr17a05LkiRJ2ziD+BbQ9IFjGLnf/m/Z8Y4IRu7XRNMHphaamSRJkrZVBvEtoPMSFUtSJEmS1DWD+Bby1hIVS1IkSZLUNYP4FtReogJYkiJJkqQNMohvQRHB1M9+gf0mf4Cpn7UkRZIkSV3zOeJb2A5D383Uz3y+9DQkSZK0jXNHXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpAIO4JEmSVIBBXJIkSSrAIC5JkiQVYBCXJEmSCjCIS5IkSQUYxCVJkqQCDOKSJElSAQZxSZIkqQCDuCRJklSAQVySJEkqwCAuSZIkFWAQlyRJkgowiEuSJEkFGMQlSZKkAgzikiRJUgEGcUmSJKkAg7gkSZJUgEFckiRJKsAgLkmSJBVgEJckSZIKMIhLkiRJBRjEJUmSpAIM4pIkSVIBBnFJkiSpgLqCeERMjYjHI2J5RMzs5PyeETE/IpZExD0RMaLm3JURsbR6nVbTHhExOyKeiIjHIuJzVfvkiFgb8f+3d/+xXtV1HMefrwGaMBsJ0Q/IksZQ54CICHORYjZ/MEmqScuWLWNzNn801nJttdictbnSrdbm1GZb+SNKY60MRkZslQkCSyQjzeSKiWXC0FJvvPrj87l1x6j7vdA9n+C+Htt33/P5fM/3u/f3vO/5nvc953PO0Zb6+HyvcUREREREHCnGDjWDpDHA14FzgD7gQUmrbT8yaLYbgG/Zvl3SIuB64KOSLgDmAnOAY4H1kn5sey9wKfAm4GTb+yVNGfR5G2wvPoQ4IiIiIiKOCL3sEZ8P/N7247ZfBu4Elhwwz6nAujp9/6DXTwXW2+63/QKwFTi3vnY5sNL2fgDbu/8HcUREREREHBGG3CMOTAV2Dmr3Ae88YJ6twAeAm4CLgOMlTar9X5D0FWA8cBYwsAf7rcDFki4CngWutL2jvna6pK3ALmCF7W09xgGApOXA8trcJ+nRHr5nDN9k4M+tgxjlkoP2koP2koP2koP2koP2Zg73Db0U4jpInw9orwC+JulS4OfAU0C/7TWS3gH8glJs/xLor+85Fvi77XmSlgK3Ae8GHgLebHufpPOBe4EZPcZROu2bgZt7+G5xGCRttD2vdRyjWXLQXnLQXnLQXnLQXnLQnqSNw31PL0NT+ihjuQdMo+yp/hfbu2wvtf024HO1b099vs72HNvnUIrpgb3efcD36vQ9wKw6/17b++r0j4Bxkib3EkdERERExJGil0L8QWCGpJMkHQMsA1YPnkHSZEkDn3UtZe82ksbUISpImkUpttfU+e4FFtXp9wC/q/O9XpLq9Pwa4196iSMiIiIi4kgx5NAU2/2SPgX8BBgD3GZ7m6SVwEbbq4EzgeslmTI05Yr69nHAhlpX7wUusT0wNOVLwLclXQPsAy6r/R8ELpfUD/wNWGbbwEHjOLyvH4cpw3/aSw7aSw7aSw7aSw7aSw7aG3YOVGrciIiIiIjoUu6sGRERERHRQArxiIiIiIgGUojHkCS9StKvJW2VtE3SF2v/SZIekLRD0l31JNoYQfUE6M2SfljbyUHHJD0h6TeStgxcqkrSCZLW1jyslfSa1nEerSRNlLRK0m8lbZd0epZ/tyTNrH//A4+9kq5OHrol6Zq6TX5Y0h11W51tQkckXVWX/TZJV9e+Ya8DKcSjFy8Bi2zPBuYA50paAHwZ+KrtGcBfgU80jHG0uArYPqidHLRxVr0s68A1ez8LrKt5WFfbMTJuAu6zfTIwm7I+ZPl3yPaj9e9/DvB24EXKZYiTh45ImgpcCcyzfRrlIhbLyDahE5JOAz5Juev7bGCxpBkcwjqQQjyG5GJfbY6rD1MuP7mq9t8OvL9BeKOGpGnABcAttS2Sg/8XSyjLH5KHESPp1cBC4FYA2y/bfp4s/5bOBh6z/UeSh66NBY6TNJZy9/KnyTahK6cAv7L9Yr0a4HrKneWHvQ6kEI+e1CERW4DdwFrgMeD5QZej7AOmtopvlLgR+Aywv7YnkRy0YGCNpE2Slte+19l+GqA+T2kW3dFtOuUuzd+sQ7RukTSBLP+WlgF31OnkoSO2nwJuAJ6kFOB7gE1km9CVh4GFkiZJGg+cT7np5LDXgRTi0RPb/6iHIadRDsWccrDZuo1q9JC0GNhte9Pg7oPMmhyMvDNszwXOA66QtLB1QKPIWGAu8I16J+cXyPCHZur44wuB77aOZbSpY4+XACcBbwQmUH6TDpRtwgiwvZ0yDGgtcB+wFej/r2/6D1KIx7DUw8A/AxYAE+shMSgF+q5WcY0CZwAXSnoCuJNy+PFGkoPO2d5Vn3dTxsXOB56R9AaA+ry7XYRHtT6gz/YDtb2KUphn+bdxHvCQ7WdqO3noznuBP9h+1vYrwPeBd5FtQmds32p7ru2FwHPADg5hHUghHkOS9FpJE+v0cZQfgO3A/ZQ7oQJ8DPhBmwiPfravtT3N9lsoh4J/avsjJAedkjRB0vED08D7KIcoV1OWPyQPI8b2n4CdkmbWrrOBR8jyb+XD/HtYCiQPXXoSWCBpfD1faGBdyDahI5Km1OcTgaWUdWHY60DurBlDkjSLctLBGMo/b3fbXilpOmXv7AnAZuAS2y+1i3R0kHQmsML24uSgW3V531ObY4Hv2L5O0iTgbuBEygbyQ7afaxTmUU3SHMoJy8cAjwMfp/4ukeXfmToudicw3fae2pf1oEP1UsIXU4ZEbAYuo4wJzzahA5I2UM7VegX4tO11h7IOpBCPiIiIiGggQ1MiIiIiIhpIIR4RERER0UAK8YiIiIiIBlKIR0REREQ0kEI8IiIiIqKBFOIREREREQ2kEI+IiIiIaOCfTJsCTz5SgmsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([21, 90, 0.9965, 0.9985])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
