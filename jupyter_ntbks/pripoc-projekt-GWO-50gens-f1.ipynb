{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # fitness is the macro avg of f1-score\n",
    "                fitness = f1_score(y_test, y_pred, average='macro')\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 50, num_eval = 50):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 39 features - 0.9991253418722995\n",
      "2 . run = 40 features - 0.9984694546447104\n",
      "3 . run = 49 features - 0.998906723241311\n",
      "4 . run = 51 features - 0.9984694125378355\n",
      "5 . run = 46 features - 0.9986880859982841\n",
      "---------------------------------------\n",
      "BEST --> 39 FEATURES - fitness = 0.9991253418722995\n",
      "executed time = 548.1626079082489 sec\n",
      "---------------------------------------\n",
      "39 features, f1 = 0.9991253418722995\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=40))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 43 features - 0.9984693698437774\n",
      "2 . run = 49 features - 0.9986880128084492\n",
      "3 . run = 39 features - 0.9984694546447104\n",
      "4 . run = 44 features - 0.9986881218382724\n",
      "5 . run = 51 features - 0.9986881218382724\n",
      "---------------------------------------\n",
      "BEST --> 44 FEATURES - fitness = 0.9986881218382724\n",
      "executed time = 581.321700334549 sec\n",
      "---------------------------------------\n",
      "44 features, f1 = 0.9986881218382724\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 49 features - 0.9986880859982841\n",
      "2 . run = 38 features - 0.998906723241311\n",
      "3 . run = 44 features - 0.9986880859982841\n",
      "4 . run = 44 features - 0.9984694961644989\n",
      "5 . run = 43 features - 0.9980321559717704\n",
      "---------------------------------------\n",
      "BEST --> 38 FEATURES - fitness = 0.998906723241311\n",
      "executed time = 604.1065402030945 sec\n",
      "---------------------------------------\n",
      "38 features, f1 = 0.998906723241311\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 49 features - 0.9989067533176503\n",
      "2 . run = 53 features - 0.9986881218382724\n",
      "3 . run = 46 features - 0.9984694546447104\n",
      "4 . run = 49 features - 0.9982507813310453\n",
      "5 . run = 43 features - 0.998906723241311\n",
      "---------------------------------------\n",
      "BEST --> 49 FEATURES - fitness = 0.9989067533176503\n",
      "executed time = 605.9117591381073 sec\n",
      "---------------------------------------\n",
      "49 features, f1 = 0.9989067533176503\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 43 features - 0.9986880859982841\n",
      "2 . run = 39 features - 0.9984694125378355\n",
      "3 . run = 47 features - 0.9982508291176966\n",
      "4 . run = 48 features - 0.9984693698437774\n",
      "5 . run = 44 features - 0.9984694546447104\n",
      "---------------------------------------\n",
      "BEST --> 43 FEATURES - fitness = 0.9986880859982841\n",
      "executed time = 621.6727221012115 sec\n",
      "---------------------------------------\n",
      "43 features, f1 = 0.9986880859982841\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (39, 0.9991253418722995, 'gwo'),\n",
       " (44, 0.9986881218382724, 'ga'),\n",
       " (38, 0.998906723241311, 'fa'),\n",
       " (49, 0.9989067533176503, 'pso'),\n",
       " (43, 0.9986880859982841, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, 0.9991253418722995, 'gwo'),\n",
       " (49, 0.9989067533176503, 'pso'),\n",
       " (38, 0.998906723241311, 'fa'),\n",
       " (44, 0.9986881218382724, 'ga'),\n",
       " (43, 0.9986880859982841, 'ba'),\n",
       " (88, 0.9982508762334465, 'all')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([36, 90, 0.9982, 0.9992])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
