{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 50, num_eval = 50):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 37 features - 1.0007532624398199\n",
      "2 . run = 30 features - 1.007601654159853\n",
      "3 . run = 35 features - 1.0021125002173032\n",
      "4 . run = 35 features - 1.0012467874090012\n",
      "5 . run = 33 features - 1.0025535284723044\n",
      "---------------------------------------\n",
      "BEST --> 30 FEATURES - fitness = 1.007601654159853\n",
      "executed time = 1246.5759847164154 sec\n",
      "---------------------------------------\n",
      "30 features, f1 = 0.9982508291176966\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=8))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 36 features - 1.0005476191310214\n",
      "2 . run = 42 features - 0.999653550110868\n",
      "3 . run = 39 features - 1.0012653077024036\n",
      "4 . run = 37 features - 1.000969610910843\n",
      "5 . run = 32 features - 1.0049024102766024\n",
      "---------------------------------------\n",
      "BEST --> 32 FEATURES - fitness = 1.0049024102766024\n",
      "executed time = 1313.211343050003 sec\n",
      "---------------------------------------\n",
      "32 features, f1 = 0.9973761719965681\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 37 features - 1.0016191256809523\n",
      "2 . run = 39 features - 1.000182945783678\n",
      "3 . run = 40 features - 0.9991859056231346\n",
      "4 . run = 38 features - 0.9996946296790663\n",
      "5 . run = 38 features - 1.0009932957699914\n",
      "---------------------------------------\n",
      "BEST --> 37 FEATURES - fitness = 1.0016191256809523\n",
      "executed time = 1285.3765864372253 sec\n",
      "---------------------------------------\n",
      "37 features, f1 = 0.9978134766638067\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 33 features - 1.00515142676493\n",
      "2 . run = 34 features - 1.0037176348719883\n",
      "3 . run = 28 features - 1.009047544747342\n",
      "4 . run = 38 features - 1.0009932366340106\n",
      "5 . run = 35 features - 1.0031945836154368\n",
      "---------------------------------------\n",
      "BEST --> 28 FEATURES - fitness = 1.009047544747342\n",
      "executed time = 1224.6883471012115 sec\n",
      "---------------------------------------\n",
      "28 features, f1 = 0.9975949225442127\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 38 features - 1.00056044594351\n",
      "2 . run = 37 features - 1.000969610910843\n",
      "3 . run = 31 features - 1.0025426000103517\n",
      "4 . run = 38 features - 1.0012097819976544\n",
      "5 . run = 36 features - 1.0018469256842237\n",
      "---------------------------------------\n",
      "BEST --> 31 FEATURES - fitness = 1.0025426000103517\n",
      "executed time = 1112.1728947162628 sec\n",
      "---------------------------------------\n",
      "31 features, f1 = 0.9940964679153113\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (30, 0.9982508291176966, 'gwo'),\n",
       " (32, 0.9973761719965681, 'ga'),\n",
       " (37, 0.9978134766638067, 'fa'),\n",
       " (28, 0.9975949225442127, 'pso'),\n",
       " (31, 0.9940964679153113, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (30, 0.9982508291176966, 'gwo'),\n",
       " (37, 0.9978134766638067, 'fa'),\n",
       " (28, 0.9975949225442127, 'pso'),\n",
       " (32, 0.9973761719965681, 'ga'),\n",
       " (31, 0.9940964679153113, 'ba')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([26, 90, 0.9938, 0.9984])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
