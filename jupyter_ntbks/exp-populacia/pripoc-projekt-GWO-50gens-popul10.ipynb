{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 50, num_eval = 50):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 31 features - 1.0038411252102124\n",
      "2 . run = 30 features - 1.0073851141493497\n",
      "3 . run = 31 features - 1.0062223179081349\n",
      "4 . run = 32 features - 1.0055517264725795\n",
      "5 . run = 36 features - 1.0011975017978656\n",
      "---------------------------------------\n",
      "BEST --> 30 FEATURES - fitness = 1.0073851141493497\n",
      "executed time = 1242.3009884357452 sec\n",
      "---------------------------------------\n",
      "30 features, f1 = 0.9980321018343599\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=10))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 31 features - 1.0053566582206028\n",
      "2 . run = 36 features - 1.0024963317052566\n",
      "3 . run = 37 features - 1.0005367518104775\n",
      "4 . run = 36 features - 1.0018468547210468\n",
      "5 . run = 35 features - 1.0021123357988933\n",
      "---------------------------------------\n",
      "BEST --> 31 FEATURES - fitness = 1.0053566582206028\n",
      "executed time = 1307.2759733200073 sec\n",
      "---------------------------------------\n",
      "31 features, f1 = 0.996938950955969\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 33 features - 1.0042855753925088\n",
      "2 . run = 36 features - 1.0007646759370896\n",
      "3 . run = 38 features - 1.001859063895329\n",
      "4 . run = 35 features - 0.9992978712877107\n",
      "5 . run = 38 features - 1.0014261682545769\n",
      "---------------------------------------\n",
      "BEST --> 33 FEATURES - fitness = 1.0042855753925088\n",
      "executed time = 1294.3765919208527 sec\n",
      "---------------------------------------\n",
      "33 features, f1 = 0.9975948572988306\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 32 features - 1.0049024812397793\n",
      "2 . run = 28 features - 1.007964625442717\n",
      "3 . run = 29 features - 1.0057991078809965\n",
      "4 . run = 34 features - 1.0041506737676962\n",
      "5 . run = 32 features - 1.0046860593767288\n",
      "---------------------------------------\n",
      "BEST --> 28 FEATURES - fitness = 1.007964625442717\n",
      "executed time = 1232.879076719284 sec\n",
      "---------------------------------------\n",
      "28 features, f1 = 0.996501064660753\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 35 features - 1.0029782581760065\n",
      "2 . run = 33 features - 1.0038527260433954\n",
      "3 . run = 33 features - 1.00277028208157\n",
      "4 . run = 29 features - 1.0070977956129006\n",
      "5 . run = 34 features - 1.0026351385772063\n",
      "---------------------------------------\n",
      "BEST --> 29 FEATURES - fitness = 1.0070977956129006\n",
      "executed time = 1129.1643843650818 sec\n",
      "---------------------------------------\n",
      "29 features, f1 = 0.9967201697239331\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (30, 0.9980321018343599, 'gwo'),\n",
       " (31, 0.996938950955969, 'ga'),\n",
       " (33, 0.9975948572988306, 'fa'),\n",
       " (28, 0.996501064660753, 'pso'),\n",
       " (29, 0.9967201697239331, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (30, 0.9980321018343599, 'gwo'),\n",
       " (33, 0.9975948572988306, 'fa'),\n",
       " (31, 0.996938950955969, 'ga'),\n",
       " (29, 0.9967201697239331, 'ba'),\n",
       " (28, 0.996501064660753, 'pso')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([26, 90, 0.9963, 0.9984])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
