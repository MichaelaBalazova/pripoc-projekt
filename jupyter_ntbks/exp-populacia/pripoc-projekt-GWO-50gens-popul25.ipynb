{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, GeneticAlgorithm, FireflyAlgorithm, ParticleSwarmOptimization, BatAlgorithm\n",
    "from NiaPy.task import Task, StoppingTask, OptimizationType\n",
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "model = \"C:/Users/miska/OneDrive/Dokumenty/pripoc-projekt/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(model + 'social_model_all_features.csv', sep = ',')\n",
    "text = pd.read_csv(model + 'text_model_all_features.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to drop the label from the text models, because we have it in the social ones\n",
    "text = text.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with all social and all text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = social.merge(text, on='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>louvain</th>\n",
       "      <th>labelPropagation</th>\n",
       "      <th>triangles</th>\n",
       "      <th>clustCoeff</th>\n",
       "      <th>scc</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>betweeness_out</th>\n",
       "      <th>betweeness_both</th>\n",
       "      <th>closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>http://www.addictinginfo.org</th>\n",
       "      <th>http://www.chicksontheright.com</th>\n",
       "      <th>http://www.ifyouonlynews.com</th>\n",
       "      <th>http://www.opposingviews.com</th>\n",
       "      <th>http://www.proudcons.com</th>\n",
       "      <th>http://www.thepoliticalinsider.com</th>\n",
       "      <th>http://www.yesimright.com</th>\n",
       "      <th>https://goo.gl</th>\n",
       "      <th>https://ihavethetruth.com</th>\n",
       "      <th>https://www.washingtonpost.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15169</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9809</td>\n",
       "      <td>32</td>\n",
       "      <td>292</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49276</td>\n",
       "      <td>4786</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15169</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>10780</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>315057</td>\n",
       "      <td>55039</td>\n",
       "      <td>393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15169</td>\n",
       "      <td>9238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>215</td>\n",
       "      <td>296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15252</td>\n",
       "      <td>15253</td>\n",
       "      <td>15169</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>7001</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15253</td>\n",
       "      <td>15254</td>\n",
       "      <td>10574</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5448</td>\n",
       "      <td>280</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15254</td>\n",
       "      <td>15255</td>\n",
       "      <td>15169</td>\n",
       "      <td>15285</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>15254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15255</td>\n",
       "      <td>15256</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>117</td>\n",
       "      <td>387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15256</td>\n",
       "      <td>15257</td>\n",
       "      <td>15169</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15257 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  louvain  labelPropagation  triangles  clustCoeff    scc  \\\n",
       "0           1    15169                 0          2         333      0   \n",
       "1           2     9809                32        292          69      1   \n",
       "2           3    15169                21          0           0      2   \n",
       "3           4    10574                32      10780          31      1   \n",
       "4           5    15169              9238          0           0      4   \n",
       "...       ...      ...               ...        ...         ...    ...   \n",
       "15252   15253    15169                32         42         166      1   \n",
       "15253   15254    10574                32          7         106      1   \n",
       "15254   15255    15169             15285          4         400  15254   \n",
       "15255   15256    15169                82          7         194      1   \n",
       "15256   15257    15169                82         18         230      1   \n",
       "\n",
       "       unionFind  betweeness_out  betweeness_both  closeness  ...  \\\n",
       "0              0               0               27        368  ...   \n",
       "1              0           49276             4786        388  ...   \n",
       "2              0               0                0        321  ...   \n",
       "3              0          315057            55039        393  ...   \n",
       "4              0             227              215        296  ...   \n",
       "...          ...             ...              ...        ...  ...   \n",
       "15252          0             150             7001        434  ...   \n",
       "15253          0            5448              280        345  ...   \n",
       "15254          0               0                5        380  ...   \n",
       "15255          0             802              117        387  ...   \n",
       "15256          0              12              114        381  ...   \n",
       "\n",
       "       http://www.addictinginfo.org  http://www.chicksontheright.com  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "15252                           0.0                              0.0   \n",
       "15253                           0.0                              0.0   \n",
       "15254                           0.0                              0.0   \n",
       "15255                           0.0                              0.0   \n",
       "15256                           0.0                              0.0   \n",
       "\n",
       "       http://www.ifyouonlynews.com  http://www.opposingviews.com  \\\n",
       "0                               0.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "...                             ...                           ...   \n",
       "15252                           0.0                           0.0   \n",
       "15253                           0.0                           0.0   \n",
       "15254                           0.0                           0.0   \n",
       "15255                           0.0                           0.0   \n",
       "15256                           0.0                           0.0   \n",
       "\n",
       "       http://www.proudcons.com  http://www.thepoliticalinsider.com  \\\n",
       "0                           0.0                                 0.0   \n",
       "1                           0.0                                 0.0   \n",
       "2                           0.0                                 0.0   \n",
       "3                           0.0                                 0.0   \n",
       "4                           0.0                                 0.0   \n",
       "...                         ...                                 ...   \n",
       "15252                       0.0                                 0.0   \n",
       "15253                       0.0                                 0.0   \n",
       "15254                       0.0                                 0.0   \n",
       "15255                       0.0                                 0.0   \n",
       "15256                       0.0                                 0.0   \n",
       "\n",
       "       http://www.yesimright.com https://goo.gl https://ihavethetruth.com  \\\n",
       "0                            0.0            0.0                       0.0   \n",
       "1                            0.0            0.0                       0.0   \n",
       "2                            0.0            0.0                       0.0   \n",
       "3                            0.0            0.0                       0.0   \n",
       "4                            0.0            0.0                       0.0   \n",
       "...                          ...            ...                       ...   \n",
       "15252                        0.0            0.0                       0.0   \n",
       "15253                        0.0            0.0                       0.0   \n",
       "15254                        0.0            0.0                       0.0   \n",
       "15255                        0.0            0.0                       0.0   \n",
       "15256                        0.0            0.0                       0.0   \n",
       "\n",
       "       https://www.washingtonpost.com  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "15252                             0.0  \n",
       "15253                             0.0  \n",
       "15254                             0.0  \n",
       "15255                             0.0  \n",
       "15256                             0.0  \n",
       "\n",
       "[15257 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors_len</th>\n",
       "      <th>avg_authors_len</th>\n",
       "      <th>avg_numbers_cnt_text</th>\n",
       "      <th>avg_numbers_cnt_title</th>\n",
       "      <th>avg_text_len</th>\n",
       "      <th>avg_text_special</th>\n",
       "      <th>avg_title_len</th>\n",
       "      <th>avg_title_special</th>\n",
       "      <th>avg_wcount_text</th>\n",
       "      <th>avg_wcount_title</th>\n",
       "      <th>...</th>\n",
       "      <th>special_text</th>\n",
       "      <th>special_title</th>\n",
       "      <th>text_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>triangles</th>\n",
       "      <th>unionFind</th>\n",
       "      <th>uppercount_text</th>\n",
       "      <th>uppercount_title</th>\n",
       "      <th>wordcount_text</th>\n",
       "      <th>wordcount_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>777</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19923.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>19923</td>\n",
       "      <td>63</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>3400</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11042</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2236</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>379</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12724</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2028</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>378</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>326</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1436.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2873</td>\n",
       "      <td>108</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13418</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5390</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3346</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>9</td>\n",
       "      <td>532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4150</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3634</td>\n",
       "      <td>63</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>557</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10679 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       authors_len  avg_authors_len  avg_numbers_cnt_text  \\\n",
       "777              6              6.0                  45.0   \n",
       "11042            7              7.0                   0.0   \n",
       "12724            2              2.0                   1.0   \n",
       "6138             0              0.0                   3.0   \n",
       "4019             1              1.0                   0.0   \n",
       "...            ...              ...                   ...   \n",
       "5191             0              0.0                   9.5   \n",
       "13418            2              2.0                   8.0   \n",
       "5390             3              3.0                  19.0   \n",
       "860              4              4.0                  20.0   \n",
       "7270             3              3.0                  14.0   \n",
       "\n",
       "       avg_numbers_cnt_title  avg_text_len  avg_text_special  avg_title_len  \\\n",
       "777                      0.0       19923.0              12.0           63.0   \n",
       "11042                    0.0        2236.0               3.0           52.0   \n",
       "12724                    0.0        1024.0               0.0           73.0   \n",
       "6138                     0.0        2028.0               2.0           57.0   \n",
       "4019                     0.0        1986.0               0.0           70.0   \n",
       "...                      ...           ...               ...            ...   \n",
       "5191                     0.0        1436.5               6.0           54.0   \n",
       "13418                    0.0        1627.0               1.0           68.0   \n",
       "5390                     0.0        3346.0               1.0           60.0   \n",
       "860                      0.0        4150.0               7.0           66.0   \n",
       "7270                     0.0        3634.0               1.0           63.0   \n",
       "\n",
       "       avg_title_special  avg_wcount_text  avg_wcount_title  ...  \\\n",
       "777                  0.0           3400.0              11.0  ...   \n",
       "11042                0.0            379.0               8.0  ...   \n",
       "12724                0.0            174.0              12.0  ...   \n",
       "6138                 0.0            378.0              11.0  ...   \n",
       "4019                 0.0            326.0              12.0  ...   \n",
       "...                  ...              ...               ...  ...   \n",
       "5191                 0.0            260.5               9.0  ...   \n",
       "13418                0.0            261.0              11.0  ...   \n",
       "5390                 0.0            532.0               9.0  ...   \n",
       "860                  0.0            688.0              10.0  ...   \n",
       "7270                 0.0            557.0              10.0  ...   \n",
       "\n",
       "       special_text  special_title  text_len  title_len  triangles  unionFind  \\\n",
       "777              12              0     19923         63        235          0   \n",
       "11042             3              0      2236         52         16          0   \n",
       "12724             0              0      1024         73         16          0   \n",
       "6138              2              0      2028         57         27          0   \n",
       "4019              0              0      1986         70        570          0   \n",
       "...             ...            ...       ...        ...        ...        ...   \n",
       "5191             12              0      2873        108        229          0   \n",
       "13418             1              0      1627         68          8          0   \n",
       "5390              1              0      3346         60          0          0   \n",
       "860               7              0      4150         66          0          0   \n",
       "7270              1              0      3634         63       1186          0   \n",
       "\n",
       "       uppercount_text  uppercount_title  wordcount_text  wordcount_title  \n",
       "777                482                12            3400               11  \n",
       "11042               79                 8             379                8  \n",
       "12724               45                 3             174               12  \n",
       "6138                60                14             378               11  \n",
       "4019                38                12             326               12  \n",
       "...                ...               ...             ...              ...  \n",
       "5191               115                21             521               18  \n",
       "13418               60                 3             261               11  \n",
       "5390               129                 9             532                9  \n",
       "860                163                12             688               10  \n",
       "7270               145                10             557               10  \n",
       "\n",
       "[10679 rows x 88 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding some features from being in the 'X'\n",
    "X_columns = combined.columns.difference(['userId', 'label', 'followingList', 'followersList', 'source'])\n",
    "\n",
    "X = combined[X_columns] \n",
    "y = combined['label']\n",
    "\n",
    "number_of_cols = len(X_columns)\n",
    "print(number_of_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1macro_xgbclassif(X__train=X_train, X__test = X_test):\n",
    "    xg = XGBClassifier()\n",
    "    xg.fit(X__train,y_train)\n",
    "    y_pred = xg.predict(X__test)\n",
    "    num_of_features = X__train.shape[1]\n",
    "    return num_of_features, f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of tuples with number of features and their f1-score\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 features, f1 = 0.9982508762334465\n"
     ]
    }
   ],
   "source": [
    "num, f1 = get_f1macro_xgbclassif()\n",
    "all_scores.append((num, f1, 'all'))\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Benchmark for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_under_threshold(values, thr):\n",
    "    indexes = []\n",
    "    for idx, val in enumerate(values):\n",
    "        if val < thr:\n",
    "            indexes.append(idx)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionBenchmark(Benchmark):\n",
    "    def __init__(self, threshold):\n",
    "        self.Lower = 0\n",
    "        self.Upper = 1\n",
    "        self.threshold = threshold\n",
    "        super().__init__(self.Lower, self.Upper)\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(D, solution):\n",
    "            selected_indexes = get_scores_under_threshold(solution, self.threshold)\n",
    "            selected_features = len(selected_indexes)\n",
    "            all_features = number_of_cols\n",
    "            \n",
    "            X_train_new = X_train.iloc[:, selected_indexes]\n",
    "            X_test_new = X_test.iloc[:, selected_indexes]\n",
    "            \n",
    "            alpha = 0.99\n",
    "            beta = 0.01\n",
    "                                \n",
    "            if X_train_new.shape[1] > 0:  # Check if no features were selected\n",
    "                classifier = XGBClassifier()\n",
    "                classifier.fit(X_train_new, y_train)\n",
    "                y_pred = classifier.predict(X_test_new)\n",
    "                # calcutaing the fitness function\n",
    "                f1 = f1_score(y_test, y_pred, average='macro')\n",
    "                classif_part = alpha * f1\n",
    "                features_part = beta * ((abs(all_features - selected_features)) / selected_features)\n",
    "                fitness = classif_part + features_part\n",
    "                # print(classif_part, features_part, ' = ', selected_features, ' features - ', (1 - fitness))\n",
    "                inverted_fitness = (1 - fitness)\n",
    "                return inverted_fitness\n",
    "            else:\n",
    "                return math.inf\n",
    "        return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionOptimizer():\n",
    "    def __init__(self, optimizer, benchmark = FeatureSelectionBenchmark, \n",
    "                 threshold = 0.5, num_iter = 5, num_gen = 50, num_eval = 50):\n",
    "        self.benchmark = benchmark\n",
    "        self.optimizer = optimizer\n",
    "        self.threshold = threshold\n",
    "        self.num_iter = num_iter\n",
    "        self.num_gen = num_gen\n",
    "        self.num_eval = num_eval\n",
    "\n",
    "    def run(self):\n",
    "        # D (int): Dimension of the problem. - the number of features\n",
    "        # nFES (int): Maximum number of function evaluations.\n",
    "        # nGEN (int): Maximum number of algorithm iterations/generations.\n",
    "        # NP : population size\n",
    "        # using inverted fitness function, because optType=OptimizationType.MAXIMIZATION is not working\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        best_scores = []\n",
    "        best_fitness = 0\n",
    "\n",
    "        for i in range (0, self.num_iter):\n",
    "            task = StoppingTask(D=number_of_cols, nFES=self.num_eval, nGEN=self.num_gen,\n",
    "                                optType=OptimizationType.MINIMIZATION, \n",
    "                                benchmark=FeatureSelectionBenchmark(self.threshold))\n",
    "            algo = self.optimizer\n",
    "            scores, fitness = algo.run(task)\n",
    "            selected_scores = [x for x in scores if x < self.threshold]\n",
    "            inverted_fitness = (1 - fitness)\n",
    "            print((i + 1), '. run =', len(selected_scores), 'features -', inverted_fitness)\n",
    "\n",
    "            if (inverted_fitness > best_fitness):\n",
    "                best_fitness = inverted_fitness\n",
    "                best_scores = scores\n",
    "                \n",
    "        end = time.time()\n",
    "\n",
    "        indexes = get_scores_under_threshold(best_scores, self.threshold)\n",
    "        names_columns = list(X_train.iloc[:, indexes].columns.values)\n",
    "        return best_fitness, len(names_columns), names_columns, indexes, end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 37 features - 1.0003203308192536\n",
      "2 . run = 33 features - 1.0040690769432692\n",
      "3 . run = 36 features - 1.0011977623060841\n",
      "4 . run = 34 features - 1.0041506264589113\n",
      "5 . run = 34 features - 1.003501129740996\n",
      "---------------------------------------\n",
      "BEST --> 34 FEATURES - fitness = 1.0041506264589113\n",
      "executed time = 551.9893460273743 sec\n",
      "---------------------------------------\n",
      "34 features, f1 = 0.9982507813310453\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GreyWolfOptimizer(NP=25))\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'gwo'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneticAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 34 features - 1.0017693310499556\n",
      "2 . run = 36 features - 1.0027127179621793\n",
      "3 . run = 30 features - 1.0047873617693523\n",
      "4 . run = 38 features - 1.0005603050134446\n",
      "5 . run = 34 features - 1.0019862832073205\n",
      "---------------------------------------\n",
      "BEST --> 30 FEATURES - fitness = 1.0047873617693523\n",
      "executed time = 538.1590056419373 sec\n",
      "---------------------------------------\n",
      "30 features, f1 = 0.9954081095313323\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = GeneticAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ga'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FireflyAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 33 features - 1.005367871804968\n",
      "2 . run = 33 features - 1.0021209469614563\n",
      "3 . run = 38 features - 0.9996942485511483\n",
      "4 . run = 38 features - 1.0007768034626843\n",
      "5 . run = 34 features - 1.0024188040304753\n",
      "---------------------------------------\n",
      "BEST --> 33 FEATURES - fitness = 1.005367871804968\n",
      "executed time = 553.1291170120239 sec\n",
      "---------------------------------------\n",
      "33 features, f1 = 0.9986880859982841\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = FireflyAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'fa'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 31 features - 1.0057893621349232\n",
      "2 . run = 31 features - 1.004490712189097\n",
      "3 . run = 26 features - 1.009083504760272\n",
      "4 . run = 28 features - 1.008614477051706\n",
      "5 . run = 31 features - 1.0057895780139727\n",
      "---------------------------------------\n",
      "BEST --> 26 FEATURES - fitness = 1.009083504760272\n",
      "executed time = 310.29173731803894 sec\n",
      "---------------------------------------\n",
      "26 features, f1 = 0.9951892433475942\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = ParticleSwarmOptimization())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'pso'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . run = 35 features - 1.001679404178327\n",
      "2 . run = 34 features - 1.0026354102945978\n",
      "3 . run = 32 features - 1.002737486494671\n",
      "4 . run = 36 features - 1.002496278856497\n",
      "5 . run = 36 features - 1.0007643722259836\n",
      "---------------------------------------\n",
      "BEST --> 32 FEATURES - fitness = 1.002737486494671\n",
      "executed time = 339.13331031799316 sec\n",
      "---------------------------------------\n",
      "32 features, f1 = 0.9951893802976475\n"
     ]
    }
   ],
   "source": [
    "opti = FeatureSelectionOptimizer(optimizer = BatAlgorithm())\n",
    "fitness, number_columns, names_columns, indexes, exe_time = opti.run()\n",
    "\n",
    "num, f1 = get_f1macro_xgbclassif(X__train=X_train.iloc[:, indexes], X__test=X_test.iloc[:, indexes])\n",
    "all_scores.append((num, f1, 'ba'))\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('BEST -->', number_columns, 'FEATURES - fitness =', fitness)\n",
    "print('executed time =', exe_time, 'sec')\n",
    "print('---------------------------------------')\n",
    "print(num, 'features, f1 =', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88, 0.9982508762334465, 'all'),\n",
       " (34, 0.9982507813310453, 'gwo'),\n",
       " (30, 0.9954081095313323, 'ga'),\n",
       " (33, 0.9986880859982841, 'fa'),\n",
       " (26, 0.9951892433475942, 'pso'),\n",
       " (32, 0.9951893802976475, 'ba')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 0.9986880859982841, 'fa'),\n",
       " (88, 0.9982508762334465, 'all'),\n",
       " (34, 0.9982507813310453, 'gwo'),\n",
       " (30, 0.9954081095313323, 'ga'),\n",
       " (32, 0.9951893802976475, 'ba'),\n",
       " (26, 0.9951892433475942, 'pso')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_sorted_f1 = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "all_scores_sorted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,10)\n",
    "plt.axis([25, 90, 0.9962, 0.9985])\n",
    "for x, y, desc in all_scores_sorted_f1:\n",
    "    plt.scatter(x, y, label=desc, marker=11, s=100)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
